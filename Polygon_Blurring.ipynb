{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Polygon_Blurring.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1sbh4aCDeDVLZdosZbQi2x0LAAihLbc0X",
      "authorship_tag": "ABX9TyNubuBWgUPsZ61SICLQlyuB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indl1670/PSMaker/blob/main/Polygon_Blurring.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Detectron2 설치"
      ],
      "metadata": {
        "id": "OJu5foCQxMPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install pyyaml==5.1\n",
        "# Detectron2 has not released pre-built binaries for the latest pytorch (https://github.com/facebookresearch/detectron2/issues/4053)\n",
        "# so we install from source instead. This takes a few minutes.\n",
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'\n",
        "\n",
        "# Install pre-built detectron2 that matches pytorch version, if released:\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/{CUDA_VERSION}/{TORCH_VERSION}/index.html\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUdAiMym1Wn6",
        "outputId": "da9f9d60-6403-4ce5-fd80-3c40cbe96f21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyyaml==5.1\n",
            "  Downloading PyYAML-5.1.tar.gz (274 kB)\n",
            "\u001b[K     |████████████████████████████████| 274 kB 29.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyyaml\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyyaml: filename=PyYAML-5.1-cp37-cp37m-linux_x86_64.whl size=44092 sha256=1ebe243fe55a3c0770fc5d66a6ddc806c84be8b56ba1175202537a0b1a155a7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/77/f5/10/d00a2bd30928b972790053b5de0c703ca87324f3fead0f2fd9\n",
            "Successfully built pyyaml\n",
            "Installing collected packages: pyyaml\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-5.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-qkfw8ume\n",
            "  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-qkfw8ume\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n",
            "Collecting yacs>=0.1.8\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.9)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.64.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n",
            "Collecting fvcore<0.1.6,>=0.1.5\n",
            "  Downloading fvcore-0.1.5.post20220512.tar.gz (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 7.1 MB/s \n",
            "\u001b[?25hCollecting iopath<0.1.10,>=0.1.7\n",
            "  Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n",
            "Collecting omegaconf>=2.1\n",
            "  Downloading omegaconf-2.2.2-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.6 MB/s \n",
            "\u001b[?25hCollecting hydra-core>=1.1\n",
            "  Downloading hydra_core-1.2.0-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting black==22.3.0\n",
            "  Downloading black-22.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 55.5 MB/s \n",
            "\u001b[?25hCollecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[K     |████████████████████████████████| 431 kB 63.8 MB/s \n",
            "\u001b[?25hCollecting fairscale\n",
            "  Downloading fairscale-0.4.6.tar.gz (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 66.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.5.4-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (4.1.1)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Collecting platformdirs>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from black==22.3.0->detectron2==0.6) (2.0.1)\n",
            "Collecting pathspec>=0.9.0\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from click>=8.0.0->black==22.3.0->detectron2==0.6) (4.11.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (21.3)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.7.1)\n",
            "Collecting antlr4-python3-runtime==4.9.*\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 72.8 MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.4.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from fairscale->detectron2==0.6) (1.11.0+cu113)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->click>=8.0.0->black==22.3.0->detectron2==0.6) (3.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.46.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm->detectron2==0.6) (0.12.0+cu113)\n",
            "Building wheels for collected packages: detectron2, fvcore, antlr4-python3-runtime, fairscale\n",
            "  Building wheel for detectron2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for detectron2: filename=detectron2-0.6-cp37-cp37m-linux_x86_64.whl size=5305396 sha256=949fe255abeeaafdbf11317a5a3095767cd4cb2c85160f522de882ff8721e60b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-vb4h_0l3/wheels/07/dc/32/0322cb484dbefab8b9366bfedbaff5060ac7d149d69c27ca5d\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20220512-py3-none-any.whl size=61288 sha256=67437ad5cc2859deb920f787c4469daec4adec87b54260310d85876040255417\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/20/f9/a11a0dd63f4c13678b2a5ec488e48078756505c7777b75b29e\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144575 sha256=e5bb0e4d12b29ce0b7e81f325cbcdfa05f727d8ca7148f3b70250973f6ac034b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/8d/53/2af8772d9aec614e3fc65e53d4a993ad73c61daa8bbd85a873\n",
            "  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.6-py3-none-any.whl size=307252 sha256=a49fb0fe722b0cdb413092b5196886815b7b6c501f98f53ed3d4a82b68479698\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/4f/0b/94c29ea06dfad93260cb0377855f87b7b863312317a7f69fe7\n",
            "Successfully built detectron2 fvcore antlr4-python3-runtime fairscale\n",
            "Installing collected packages: portalocker, antlr4-python3-runtime, yacs, typed-ast, platformdirs, pathspec, omegaconf, mypy-extensions, iopath, click, timm, hydra-core, fvcore, fairscale, black, detectron2\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed antlr4-python3-runtime-4.9.3 black-22.3.0 click-8.1.3 detectron2-0.6 fairscale-0.4.6 fvcore-0.1.5.post20220512 hydra-core-1.2.0 iopath-0.1.9 mypy-extensions-0.4.3 omegaconf-2.2.2 pathspec-0.9.0 platformdirs-2.5.2 portalocker-2.4.0 timm-0.5.4 typed-ast-1.5.4 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 버전 확인"
      ],
      "metadata": {
        "id": "mbtwdOZLxT0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, detectron2\n",
        "!nvcc --version\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "print(\"detectron2:\", detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-cE0lKF1lqB",
        "outputId": "aee9cc81-1d51-48e4-f8cb-4f90fb83aaa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n",
            "torch:  1.11 ; cuda:  cu113\n",
            "detectron2: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "JuZ27FrRxZfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모듈 로드"
      ],
      "metadata": {
        "id": "YwELHJM4yTra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If error occured, check current directory\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2 import model_zoo\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pickle\n",
        "import json\n",
        "import random"
      ],
      "metadata": {
        "id": "edT6U0ku2ewB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파라미터 설정"
      ],
      "metadata": {
        "id": "1jTZw15Kxbfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사전학습된 모델 파일 경로 - 수정x\n",
        "# pre-trained model file\n",
        "config_file_path = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "checkpoint_url = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "\n",
        "# 학습이 완료된 모델을 저장시킬 경로 입력\n",
        "# test result directory\n",
        "output_dir = \"./drive/MyDrive/졸업과제/output2/\"\n",
        "\n",
        "# 카테고리 개수 입입력\n",
        "# Enter the total number of objects\n",
        "num_classes = 4\n",
        "\n",
        "# 학습에 사용될 장치 설정 - 수정 x\n",
        "# Use cuda device\n",
        "device = \"cuda\"\n",
        "\n",
        "# 데이터셋 이름, 이미지 경로, 라벨링 경로 입력\n",
        "# Dataset configuration\n",
        "train_dataset_name = \"train_\" # 학습 데이터셋 이름 입력(register_coco에 한번 저장된 이름일 경우 에러를 유발하기 때문에 등록할때마다 다른 이름 작성 필요)\n",
        "train_images_path = \"./drive/MyDrive/졸업과제/Images2/\" # 학습 데이터셋 이미지 경로 입력\n",
        "train_json_annot_path = \"./drive/MyDrive/졸업과제/annotations2.json\" # 학습 데이터셋 라벨링 경로 + 라벨링 파일 이름 입력\n",
        "\n",
        "test_dataset_name =\"valid_\"\n",
        "test_images_path = \"./drive/MyDrive/졸업과제/Images2\"\n",
        "test_json_annot_path = \"./drive/MyDrive/졸업과제/annotations2.json\"\n",
        "\n",
        "# 학습 진행시 configure파일을 저장시킬 폴더 경로 입력 + configure파일 이름(학습마다 다르게 설정) 입력\n",
        "# Save configuration file\n",
        "cfg_save_path = \"./drive/MyDrive/졸업과제/cfg_file/0630.pickle\""
      ],
      "metadata": {
        "id": "4DHYJZjS15kC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터셋 등록"
      ],
      "metadata": {
        "id": "jbOxtvuCyX0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#데이터셋의 이름 변경 필요\n",
        "# Reginster train, test dataset\n",
        "register_coco_instances(name = train_dataset_name, metadata = {}, json_file = train_json_annot_path, image_root = train_images_path)\n",
        "register_coco_instances(name = test_dataset_name, metadata = {}, json_file = test_json_annot_path, image_root = test_images_path)"
      ],
      "metadata": {
        "id": "XSbZHL722hIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 이미지 출력\n",
        "# Draw samples\n",
        "def plot_samples(dataset_name, n=1):\n",
        "    dataset_custom = DatasetCatalog.get(dataset_name)\n",
        "    dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
        "    \n",
        "    for s in random.sample(dataset_custom, n):\n",
        "        img = cv2.imread(s[\"file_name\"])\n",
        "        v = Visualizer(img[:,:,::-1], metadata=dataset_custom_metadata, scale=0.5)\n",
        "        v = v.draw_dataset_dict(s)\n",
        "        plt.figure(figsize=(15, 20))\n",
        "        plt.imshow(v.get_image())\n",
        "        plt.show()\n",
        "\n",
        "# 디텍트론 학습\n",
        "# Set configuration    \n",
        "def get_train_cfg(config_file_path, checkpoint_url, train_dataset_name, test_dataset_name, num_classes, device, output_dir):\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(model_zoo.get_config_file(config_file_path))\n",
        "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(checkpoint_url)\n",
        "    cfg.DATASETS.TRAIN = (train_dataset_name,)\n",
        "    cfg.DATASETS.TEST = (test_dataset_name,)\n",
        "    \n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "    cfg.SOLVER.BASE_LR = 0.001\n",
        "    # epoch = MAX_ITER * BATCH_SIZE / TOTAL_NUM_IMAGES\n",
        "    cfg.SOLVER.MAX_ITER = 5000 # 적절한 iteration값 수정 필요\n",
        "    cfg.SOLVER.STEPS = []\n",
        "    \n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
        "    cfg.MODEL.DEVICE = device\n",
        "    cfg.OUTPUT_DIR = output_dir\n",
        "    \n",
        "    return cfg\n",
        "\n",
        "# 이미지 detect 함수\n",
        "# 개별 단일 이미지 detect 함수\n",
        "def on_image(image_path, predictor):\n",
        "    im = cv2.imread(image_path)\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:,:,::-1], metadata={}, scale=0.5)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.figure(figsize=(14,10))\n",
        "    plt.imshow(v.get_image())\n",
        "    plt.show()\n",
        "\n",
        "# 폴더 내 전체 이미지 detect및 저장 함수\n",
        "def on_image_All(image_path, predictor):\n",
        "    im = cv2.imread(image_path)\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:,:,::-1], metadata={}, scale=0.5)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "\n",
        "    return (v.get_image()) # Save multi images\n",
        "\n",
        "# 객체 블러링\n",
        "def direct_cv_blur_detector(image_path, predictor):\n",
        "    im = cv2.imread(image_path)\n",
        "    blur_img = cv2.GaussianBlur(im, (0, 0), 50)\n",
        "    outputs = predictor(im)\n",
        "    x = outputs['instances'].to('cpu')\n",
        "    instances = outputs[\"instances\"]\n",
        "\n",
        "    #원하는 값 얻는 방법.\n",
        "    mask = x.get('pred_masks').permute(1, 2, 0).to(\"cpu\").numpy()\n",
        "    num_instances = mask.shape[2]\n",
        "    mask_array_instance = []\n",
        "\n",
        "    for i in range(num_instances):\n",
        "      mask_array_instance.append(mask[:, :, i:(i+1)])\n",
        "      if str(instances.pred_classes[i])[7:8] == '3':\n",
        "        img = np.where(mask_array_instance[i] == True, 0, 1)\n",
        "        array_img = np.asarray(img)\n",
        "\n",
        "        #아래부분을 리스트로 받아서 풀면 더 빠르지 않을까 생각은 해봄. -> 0으로 함으로써 사용 x\n",
        "        im[np.where((array_img==0).all(axis=2))]= 0\n",
        "      else:\n",
        "        pass\n",
        "    return np.where(im == 0, blur_img, im)"
      ],
      "metadata": {
        "id": "t9p0tzpJ2oBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "TQY2wwKUy_ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    cfg = get_train_cfg(config_file_path, checkpoint_url, train_dataset_name,\n",
        "                        test_dataset_name, num_classes, device, output_dir)\n",
        "\n",
        "    with open(cfg_save_path, 'wb') as f:\n",
        "        pickle.dump(cfg, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "    trainer = DefaultTrainer(cfg)\n",
        "    trainer.resume_or_load(resume=False)\n",
        "\n",
        "    trainer.train()\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDkAE95r2tSq",
        "outputId": "17063ac1-9624-4190-a792-56332b4ec8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[06/30 01:41:31 d2.engine.defaults]: \u001b[0mModel:\n",
            "GeneralizedRCNN(\n",
            "  (backbone): FPN(\n",
            "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (top_block): LastLevelMaxPool()\n",
            "    (bottom_up): ResNet(\n",
            "      (stem): BasicStem(\n",
            "        (conv1): Conv2d(\n",
            "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
            "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "        )\n",
            "      )\n",
            "      (res2): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res3): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res4): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (3): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (4): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (5): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (res5): Sequential(\n",
            "        (0): BottleneckBlock(\n",
            "          (shortcut): Conv2d(\n",
            "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "          (conv1): Conv2d(\n",
            "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (1): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "        (2): BottleneckBlock(\n",
            "          (conv1): Conv2d(\n",
            "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv2): Conv2d(\n",
            "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
            "          )\n",
            "          (conv3): Conv2d(\n",
            "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
            "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (proposal_generator): RPN(\n",
            "    (rpn_head): StandardRPNHead(\n",
            "      (conv): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "    (anchor_generator): DefaultAnchorGenerator(\n",
            "      (cell_anchors): BufferList()\n",
            "    )\n",
            "  )\n",
            "  (roi_heads): StandardROIHeads(\n",
            "    (box_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (box_head): FastRCNNConvFCHead(\n",
            "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
            "      (fc_relu1): ReLU()\n",
            "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "      (fc_relu2): ReLU()\n",
            "    )\n",
            "    (box_predictor): FastRCNNOutputLayers(\n",
            "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
            "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
            "    )\n",
            "    (mask_pooler): ROIPooler(\n",
            "      (level_poolers): ModuleList(\n",
            "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
            "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
            "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
            "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
            "      )\n",
            "    )\n",
            "    (mask_head): MaskRCNNConvUpsampleHead(\n",
            "      (mask_fcn1): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn2): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn3): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (mask_fcn4): Conv2d(\n",
            "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (deconv_relu): ReLU()\n",
            "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 01:41:32 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[06/30 01:41:32 d2.data.datasets.coco]: \u001b[0mLoaded 433 images in COCO format from ./drive/MyDrive/졸업과제/annotations2.json\n",
            "\u001b[32m[06/30 01:41:32 d2.data.build]: \u001b[0mRemoved 9 images with no usable annotations. 424 images left.\n",
            "\u001b[32m[06/30 01:41:32 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
            "\u001b[36m|  category  | #instances   | category   | #instances   | category   | #instances   |\n",
            "|:----------:|:-------------|:-----------|:-------------|:-----------|:-------------|\n",
            "|   1-2-3    | 0            | 1          | 341          | 2          | 368          |\n",
            "|     3      | 1338         |            |              |            |              |\n",
            "|   total    | 2047         |            |              |            |              |\u001b[0m\n",
            "\u001b[32m[06/30 01:41:32 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
            "\u001b[32m[06/30 01:41:32 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
            "\u001b[32m[06/30 01:41:32 d2.data.common]: \u001b[0mSerializing 424 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[06/30 01:41:32 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "model_final_f10217.pkl: 178MB [01:38, 1.80MB/s]                           \n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
            "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
            "Some model parameters or buffers are not found in the checkpoint:\n",
            "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
            "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[06/30 01:43:17 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/functional.py:568: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2228.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[06/30 01:43:30 d2.utils.events]: \u001b[0m eta: 0:49:37  iter: 19  total_loss: 2.486  loss_cls: 1.519  loss_box_reg: 0.1002  loss_mask: 0.6924  loss_rpn_cls: 0.1891  loss_rpn_loc: 0.03629  time: 0.6142  data_time: 0.1043  lr: 1.9981e-05  max_mem: 2673M\n",
            "\u001b[32m[06/30 01:43:43 d2.utils.events]: \u001b[0m eta: 0:51:30  iter: 39  total_loss: 2.215  loss_cls: 1.208  loss_box_reg: 0.152  loss_mask: 0.6897  loss_rpn_cls: 0.1023  loss_rpn_loc: 0.03072  time: 0.6354  data_time: 0.1043  lr: 3.9961e-05  max_mem: 2673M\n",
            "\u001b[32m[06/30 01:43:57 d2.utils.events]: \u001b[0m eta: 0:51:59  iter: 59  total_loss: 1.605  loss_cls: 0.6139  loss_box_reg: 0.1432  loss_mask: 0.6855  loss_rpn_cls: 0.06907  loss_rpn_loc: 0.02166  time: 0.6464  data_time: 0.1183  lr: 5.9941e-05  max_mem: 2673M\n",
            "\u001b[32m[06/30 01:44:10 d2.utils.events]: \u001b[0m eta: 0:51:46  iter: 79  total_loss: 1.451  loss_cls: 0.4138  loss_box_reg: 0.2625  loss_mask: 0.6794  loss_rpn_cls: 0.06289  loss_rpn_loc: 0.0235  time: 0.6480  data_time: 0.0871  lr: 7.9921e-05  max_mem: 2673M\n",
            "\u001b[32m[06/30 01:44:23 d2.utils.events]: \u001b[0m eta: 0:51:41  iter: 99  total_loss: 1.477  loss_cls: 0.4134  loss_box_reg: 0.3249  loss_mask: 0.67  loss_rpn_cls: 0.03778  loss_rpn_loc: 0.0242  time: 0.6485  data_time: 0.0638  lr: 9.9901e-05  max_mem: 2673M\n",
            "\u001b[32m[06/30 01:44:35 d2.utils.events]: \u001b[0m eta: 0:51:21  iter: 119  total_loss: 1.535  loss_cls: 0.4053  loss_box_reg: 0.4056  loss_mask: 0.6573  loss_rpn_cls: 0.0287  loss_rpn_loc: 0.03178  time: 0.6460  data_time: 0.0214  lr: 0.00011988  max_mem: 2673M\n",
            "\u001b[32m[06/30 01:44:49 d2.utils.events]: \u001b[0m eta: 0:51:18  iter: 139  total_loss: 1.488  loss_cls: 0.3852  loss_box_reg: 0.4287  loss_mask: 0.633  loss_rpn_cls: 0.03437  loss_rpn_loc: 0.02672  time: 0.6482  data_time: 0.0489  lr: 0.00013986  max_mem: 2673M\n",
            "\u001b[32m[06/30 01:45:02 d2.utils.events]: \u001b[0m eta: 0:51:36  iter: 159  total_loss: 1.483  loss_cls: 0.3692  loss_box_reg: 0.4588  loss_mask: 0.6029  loss_rpn_cls: 0.02383  loss_rpn_loc: 0.02845  time: 0.6506  data_time: 0.0147  lr: 0.00015984  max_mem: 2676M\n",
            "\u001b[32m[06/30 01:45:15 d2.utils.events]: \u001b[0m eta: 0:51:51  iter: 179  total_loss: 1.343  loss_cls: 0.3243  loss_box_reg: 0.4139  loss_mask: 0.56  loss_rpn_cls: 0.01833  loss_rpn_loc: 0.0189  time: 0.6503  data_time: 0.0074  lr: 0.00017982  max_mem: 2676M\n",
            "\u001b[32m[06/30 01:45:28 d2.utils.events]: \u001b[0m eta: 0:51:38  iter: 199  total_loss: 1.34  loss_cls: 0.3521  loss_box_reg: 0.4774  loss_mask: 0.4902  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.02335  time: 0.6502  data_time: 0.0279  lr: 0.0001998  max_mem: 2676M\n",
            "\u001b[32m[06/30 01:45:41 d2.utils.events]: \u001b[0m eta: 0:51:37  iter: 219  total_loss: 1.275  loss_cls: 0.314  loss_box_reg: 0.4457  loss_mask: 0.4364  loss_rpn_cls: 0.02683  loss_rpn_loc: 0.0221  time: 0.6495  data_time: 0.0123  lr: 0.00021978  max_mem: 2683M\n",
            "\u001b[32m[06/30 01:45:53 d2.utils.events]: \u001b[0m eta: 0:51:24  iter: 239  total_loss: 1.25  loss_cls: 0.335  loss_box_reg: 0.5395  loss_mask: 0.3613  loss_rpn_cls: 0.01801  loss_rpn_loc: 0.01951  time: 0.6481  data_time: 0.0061  lr: 0.00023976  max_mem: 2732M\n",
            "\u001b[32m[06/30 01:46:06 d2.utils.events]: \u001b[0m eta: 0:51:11  iter: 259  total_loss: 1.18  loss_cls: 0.3229  loss_box_reg: 0.4882  loss_mask: 0.3145  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.02026  time: 0.6477  data_time: 0.0095  lr: 0.00025974  max_mem: 2732M\n",
            "\u001b[32m[06/30 01:46:19 d2.utils.events]: \u001b[0m eta: 0:50:56  iter: 279  total_loss: 1.133  loss_cls: 0.3013  loss_box_reg: 0.509  loss_mask: 0.2742  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.01825  time: 0.6463  data_time: 0.0097  lr: 0.00027972  max_mem: 2732M\n",
            "\u001b[32m[06/30 01:46:32 d2.utils.events]: \u001b[0m eta: 0:50:46  iter: 299  total_loss: 1.037  loss_cls: 0.2892  loss_box_reg: 0.431  loss_mask: 0.2465  loss_rpn_cls: 0.006346  loss_rpn_loc: 0.01867  time: 0.6467  data_time: 0.0091  lr: 0.0002997  max_mem: 2732M\n",
            "\u001b[32m[06/30 01:46:45 d2.utils.events]: \u001b[0m eta: 0:50:40  iter: 319  total_loss: 0.9982  loss_cls: 0.2569  loss_box_reg: 0.454  loss_mask: 0.22  loss_rpn_cls: 0.01243  loss_rpn_loc: 0.01609  time: 0.6473  data_time: 0.0075  lr: 0.00031968  max_mem: 2732M\n",
            "\u001b[32m[06/30 01:46:58 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 339  total_loss: 0.9837  loss_cls: 0.285  loss_box_reg: 0.4402  loss_mask: 0.226  loss_rpn_cls: 0.01377  loss_rpn_loc: 0.02381  time: 0.6483  data_time: 0.0077  lr: 0.00033966  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:47:12 d2.utils.events]: \u001b[0m eta: 0:50:30  iter: 359  total_loss: 1.083  loss_cls: 0.3052  loss_box_reg: 0.4773  loss_mask: 0.2424  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.02056  time: 0.6505  data_time: 0.0100  lr: 0.00035964  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:47:25 d2.utils.events]: \u001b[0m eta: 0:50:19  iter: 379  total_loss: 0.9492  loss_cls: 0.2966  loss_box_reg: 0.3931  loss_mask: 0.224  loss_rpn_cls: 0.007555  loss_rpn_loc: 0.01893  time: 0.6509  data_time: 0.0075  lr: 0.00037962  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:47:38 d2.utils.events]: \u001b[0m eta: 0:50:09  iter: 399  total_loss: 0.8103  loss_cls: 0.2453  loss_box_reg: 0.3384  loss_mask: 0.2171  loss_rpn_cls: 0.00917  loss_rpn_loc: 0.01662  time: 0.6512  data_time: 0.0081  lr: 0.0003996  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:47:52 d2.utils.events]: \u001b[0m eta: 0:49:56  iter: 419  total_loss: 0.6673  loss_cls: 0.2122  loss_box_reg: 0.2699  loss_mask: 0.1947  loss_rpn_cls: 0.002866  loss_rpn_loc: 0.01537  time: 0.6516  data_time: 0.0068  lr: 0.00041958  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:48:05 d2.utils.events]: \u001b[0m eta: 0:49:49  iter: 439  total_loss: 0.8346  loss_cls: 0.263  loss_box_reg: 0.3238  loss_mask: 0.2139  loss_rpn_cls: 0.00901  loss_rpn_loc: 0.02207  time: 0.6522  data_time: 0.0069  lr: 0.00043956  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:48:18 d2.utils.events]: \u001b[0m eta: 0:49:40  iter: 459  total_loss: 0.8418  loss_cls: 0.2604  loss_box_reg: 0.3426  loss_mask: 0.2095  loss_rpn_cls: 0.003738  loss_rpn_loc: 0.01956  time: 0.6527  data_time: 0.0095  lr: 0.00045954  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:48:31 d2.utils.events]: \u001b[0m eta: 0:49:22  iter: 479  total_loss: 0.8336  loss_cls: 0.248  loss_box_reg: 0.331  loss_mask: 0.2211  loss_rpn_cls: 0.006622  loss_rpn_loc: 0.01748  time: 0.6525  data_time: 0.0080  lr: 0.00047952  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:48:44 d2.utils.events]: \u001b[0m eta: 0:49:09  iter: 499  total_loss: 0.7532  loss_cls: 0.2217  loss_box_reg: 0.2799  loss_mask: 0.2157  loss_rpn_cls: 0.005631  loss_rpn_loc: 0.01546  time: 0.6524  data_time: 0.0069  lr: 0.0004995  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:48:57 d2.utils.events]: \u001b[0m eta: 0:48:57  iter: 519  total_loss: 0.7801  loss_cls: 0.2337  loss_box_reg: 0.3069  loss_mask: 0.211  loss_rpn_cls: 0.003899  loss_rpn_loc: 0.01756  time: 0.6524  data_time: 0.0073  lr: 0.00051948  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:49:11 d2.utils.events]: \u001b[0m eta: 0:48:47  iter: 539  total_loss: 0.6692  loss_cls: 0.2114  loss_box_reg: 0.2638  loss_mask: 0.1987  loss_rpn_cls: 0.002833  loss_rpn_loc: 0.01526  time: 0.6531  data_time: 0.0097  lr: 0.00053946  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:49:24 d2.utils.events]: \u001b[0m eta: 0:48:43  iter: 559  total_loss: 0.8276  loss_cls: 0.2283  loss_box_reg: 0.2989  loss_mask: 0.1856  loss_rpn_cls: 0.003849  loss_rpn_loc: 0.0178  time: 0.6535  data_time: 0.0113  lr: 0.00055944  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:49:37 d2.utils.events]: \u001b[0m eta: 0:48:23  iter: 579  total_loss: 0.6841  loss_cls: 0.1986  loss_box_reg: 0.2459  loss_mask: 0.2058  loss_rpn_cls: 0.00418  loss_rpn_loc: 0.01519  time: 0.6533  data_time: 0.0072  lr: 0.00057942  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:49:50 d2.utils.events]: \u001b[0m eta: 0:48:17  iter: 599  total_loss: 0.7031  loss_cls: 0.1953  loss_box_reg: 0.2749  loss_mask: 0.2125  loss_rpn_cls: 0.00451  loss_rpn_loc: 0.01515  time: 0.6537  data_time: 0.0082  lr: 0.0005994  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:50:03 d2.utils.events]: \u001b[0m eta: 0:48:04  iter: 619  total_loss: 0.6495  loss_cls: 0.1723  loss_box_reg: 0.2499  loss_mask: 0.1888  loss_rpn_cls: 0.004302  loss_rpn_loc: 0.01439  time: 0.6537  data_time: 0.0085  lr: 0.00061938  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:50:16 d2.utils.events]: \u001b[0m eta: 0:47:44  iter: 639  total_loss: 0.5923  loss_cls: 0.144  loss_box_reg: 0.2287  loss_mask: 0.1746  loss_rpn_cls: 0.001384  loss_rpn_loc: 0.01329  time: 0.6534  data_time: 0.0086  lr: 0.00063936  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:50:29 d2.utils.events]: \u001b[0m eta: 0:47:34  iter: 659  total_loss: 0.6885  loss_cls: 0.1819  loss_box_reg: 0.2948  loss_mask: 0.1963  loss_rpn_cls: 0.002714  loss_rpn_loc: 0.01788  time: 0.6534  data_time: 0.0085  lr: 0.00065934  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:50:43 d2.utils.events]: \u001b[0m eta: 0:47:26  iter: 679  total_loss: 0.7329  loss_cls: 0.1856  loss_box_reg: 0.298  loss_mask: 0.2199  loss_rpn_cls: 0.003758  loss_rpn_loc: 0.01893  time: 0.6539  data_time: 0.0093  lr: 0.00067932  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:50:56 d2.utils.events]: \u001b[0m eta: 0:47:14  iter: 699  total_loss: 0.6616  loss_cls: 0.1557  loss_box_reg: 0.2776  loss_mask: 0.2  loss_rpn_cls: 0.002501  loss_rpn_loc: 0.01498  time: 0.6543  data_time: 0.0068  lr: 0.0006993  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:51:09 d2.utils.events]: \u001b[0m eta: 0:47:08  iter: 719  total_loss: 0.7058  loss_cls: 0.1629  loss_box_reg: 0.3106  loss_mask: 0.2015  loss_rpn_cls: 0.002191  loss_rpn_loc: 0.01673  time: 0.6548  data_time: 0.0069  lr: 0.00071928  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:51:22 d2.utils.events]: \u001b[0m eta: 0:46:54  iter: 739  total_loss: 0.7451  loss_cls: 0.1772  loss_box_reg: 0.3211  loss_mask: 0.1995  loss_rpn_cls: 0.003147  loss_rpn_loc: 0.01603  time: 0.6544  data_time: 0.0070  lr: 0.00073926  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:51:36 d2.utils.events]: \u001b[0m eta: 0:46:42  iter: 759  total_loss: 0.6954  loss_cls: 0.1444  loss_box_reg: 0.2999  loss_mask: 0.1896  loss_rpn_cls: 0.001223  loss_rpn_loc: 0.01304  time: 0.6548  data_time: 0.0105  lr: 0.00075924  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:51:49 d2.utils.events]: \u001b[0m eta: 0:46:29  iter: 779  total_loss: 0.6146  loss_cls: 0.1876  loss_box_reg: 0.2459  loss_mask: 0.1915  loss_rpn_cls: 0.004872  loss_rpn_loc: 0.01383  time: 0.6550  data_time: 0.0083  lr: 0.00077922  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:52:02 d2.utils.events]: \u001b[0m eta: 0:46:18  iter: 799  total_loss: 0.7128  loss_cls: 0.1779  loss_box_reg: 0.3036  loss_mask: 0.199  loss_rpn_cls: 0.00409  loss_rpn_loc: 0.0173  time: 0.6555  data_time: 0.0086  lr: 0.0007992  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:52:16 d2.utils.events]: \u001b[0m eta: 0:46:04  iter: 819  total_loss: 0.5821  loss_cls: 0.1372  loss_box_reg: 0.2614  loss_mask: 0.1741  loss_rpn_cls: 0.004693  loss_rpn_loc: 0.01378  time: 0.6557  data_time: 0.0077  lr: 0.00081918  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:52:29 d2.utils.events]: \u001b[0m eta: 0:45:50  iter: 839  total_loss: 0.664  loss_cls: 0.1453  loss_box_reg: 0.2757  loss_mask: 0.1958  loss_rpn_cls: 0.003657  loss_rpn_loc: 0.01433  time: 0.6558  data_time: 0.0098  lr: 0.00083916  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:52:42 d2.utils.events]: \u001b[0m eta: 0:45:38  iter: 859  total_loss: 0.6085  loss_cls: 0.1547  loss_box_reg: 0.2578  loss_mask: 0.1925  loss_rpn_cls: 0.001793  loss_rpn_loc: 0.01245  time: 0.6557  data_time: 0.0076  lr: 0.00085914  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:52:55 d2.utils.events]: \u001b[0m eta: 0:45:25  iter: 879  total_loss: 0.6251  loss_cls: 0.1316  loss_box_reg: 0.2678  loss_mask: 0.1811  loss_rpn_cls: 0.003569  loss_rpn_loc: 0.01253  time: 0.6559  data_time: 0.0091  lr: 0.00087912  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:53:08 d2.utils.events]: \u001b[0m eta: 0:45:11  iter: 899  total_loss: 0.6622  loss_cls: 0.1405  loss_box_reg: 0.2759  loss_mask: 0.182  loss_rpn_cls: 0.001024  loss_rpn_loc: 0.01375  time: 0.6556  data_time: 0.0080  lr: 0.0008991  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:53:22 d2.utils.events]: \u001b[0m eta: 0:44:59  iter: 919  total_loss: 0.5815  loss_cls: 0.1275  loss_box_reg: 0.2676  loss_mask: 0.1742  loss_rpn_cls: 0.00235  loss_rpn_loc: 0.01204  time: 0.6558  data_time: 0.0069  lr: 0.00091908  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:53:35 d2.utils.events]: \u001b[0m eta: 0:44:45  iter: 939  total_loss: 0.5728  loss_cls: 0.1079  loss_box_reg: 0.2449  loss_mask: 0.169  loss_rpn_cls: 0.00164  loss_rpn_loc: 0.01161  time: 0.6558  data_time: 0.0073  lr: 0.00093906  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:53:48 d2.utils.events]: \u001b[0m eta: 0:44:32  iter: 959  total_loss: 0.6338  loss_cls: 0.1344  loss_box_reg: 0.2775  loss_mask: 0.1896  loss_rpn_cls: 0.001863  loss_rpn_loc: 0.01472  time: 0.6560  data_time: 0.0092  lr: 0.00095904  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:54:01 d2.utils.events]: \u001b[0m eta: 0:44:20  iter: 979  total_loss: 0.6835  loss_cls: 0.1581  loss_box_reg: 0.2881  loss_mask: 0.1956  loss_rpn_cls: 0.002395  loss_rpn_loc: 0.01867  time: 0.6562  data_time: 0.0083  lr: 0.00097902  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:54:15 d2.utils.events]: \u001b[0m eta: 0:44:09  iter: 999  total_loss: 0.7054  loss_cls: 0.1564  loss_box_reg: 0.3148  loss_mask: 0.1858  loss_rpn_cls: 0.001759  loss_rpn_loc: 0.0143  time: 0.6567  data_time: 0.0083  lr: 0.000999  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:54:29 d2.utils.events]: \u001b[0m eta: 0:44:04  iter: 1019  total_loss: 0.6957  loss_cls: 0.1599  loss_box_reg: 0.2958  loss_mask: 0.1903  loss_rpn_cls: 0.002214  loss_rpn_loc: 0.01616  time: 0.6573  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:54:42 d2.utils.events]: \u001b[0m eta: 0:43:52  iter: 1039  total_loss: 0.6264  loss_cls: 0.1316  loss_box_reg: 0.2802  loss_mask: 0.1819  loss_rpn_cls: 0.001801  loss_rpn_loc: 0.01477  time: 0.6572  data_time: 0.0064  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:54:55 d2.utils.events]: \u001b[0m eta: 0:43:39  iter: 1059  total_loss: 0.5822  loss_cls: 0.1479  loss_box_reg: 0.2412  loss_mask: 0.1865  loss_rpn_cls: 0.002489  loss_rpn_loc: 0.01516  time: 0.6572  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:55:08 d2.utils.events]: \u001b[0m eta: 0:43:26  iter: 1079  total_loss: 0.5199  loss_cls: 0.131  loss_box_reg: 0.2419  loss_mask: 0.1586  loss_rpn_cls: 0.001457  loss_rpn_loc: 0.01275  time: 0.6573  data_time: 0.0105  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:55:21 d2.utils.events]: \u001b[0m eta: 0:43:17  iter: 1099  total_loss: 0.5839  loss_cls: 0.1243  loss_box_reg: 0.2464  loss_mask: 0.177  loss_rpn_cls: 0.0009739  loss_rpn_loc: 0.01355  time: 0.6574  data_time: 0.0083  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:55:34 d2.utils.events]: \u001b[0m eta: 0:43:07  iter: 1119  total_loss: 0.5799  loss_cls: 0.1106  loss_box_reg: 0.2541  loss_mask: 0.1975  loss_rpn_cls: 0.001825  loss_rpn_loc: 0.01249  time: 0.6571  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:55:48 d2.utils.events]: \u001b[0m eta: 0:42:54  iter: 1139  total_loss: 0.6625  loss_cls: 0.1284  loss_box_reg: 0.2946  loss_mask: 0.1967  loss_rpn_cls: 0.002894  loss_rpn_loc: 0.01274  time: 0.6573  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:56:01 d2.utils.events]: \u001b[0m eta: 0:42:40  iter: 1159  total_loss: 0.5482  loss_cls: 0.1197  loss_box_reg: 0.262  loss_mask: 0.1703  loss_rpn_cls: 0.002244  loss_rpn_loc: 0.01073  time: 0.6575  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:56:14 d2.utils.events]: \u001b[0m eta: 0:42:28  iter: 1179  total_loss: 0.6137  loss_cls: 0.1408  loss_box_reg: 0.2666  loss_mask: 0.1877  loss_rpn_cls: 0.002207  loss_rpn_loc: 0.01744  time: 0.6575  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:56:27 d2.utils.events]: \u001b[0m eta: 0:42:15  iter: 1199  total_loss: 0.5321  loss_cls: 0.1118  loss_box_reg: 0.2405  loss_mask: 0.1654  loss_rpn_cls: 0.000712  loss_rpn_loc: 0.01194  time: 0.6576  data_time: 0.0099  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:56:41 d2.utils.events]: \u001b[0m eta: 0:42:05  iter: 1219  total_loss: 0.6659  loss_cls: 0.1653  loss_box_reg: 0.2991  loss_mask: 0.1991  loss_rpn_cls: 0.002086  loss_rpn_loc: 0.01589  time: 0.6581  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:56:54 d2.utils.events]: \u001b[0m eta: 0:41:56  iter: 1239  total_loss: 0.5983  loss_cls: 0.1334  loss_box_reg: 0.2792  loss_mask: 0.1755  loss_rpn_cls: 0.002556  loss_rpn_loc: 0.01399  time: 0.6582  data_time: 0.0089  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:57:08 d2.utils.events]: \u001b[0m eta: 0:41:46  iter: 1259  total_loss: 0.5686  loss_cls: 0.1285  loss_box_reg: 0.2556  loss_mask: 0.1746  loss_rpn_cls: 0.001477  loss_rpn_loc: 0.01297  time: 0.6586  data_time: 0.0083  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:57:21 d2.utils.events]: \u001b[0m eta: 0:41:33  iter: 1279  total_loss: 0.5543  loss_cls: 0.1161  loss_box_reg: 0.2516  loss_mask: 0.1795  loss_rpn_cls: 0.001197  loss_rpn_loc: 0.01353  time: 0.6585  data_time: 0.0084  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:57:35 d2.utils.events]: \u001b[0m eta: 0:41:21  iter: 1299  total_loss: 0.5529  loss_cls: 0.1251  loss_box_reg: 0.221  loss_mask: 0.1674  loss_rpn_cls: 0.002928  loss_rpn_loc: 0.01308  time: 0.6586  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:57:48 d2.utils.events]: \u001b[0m eta: 0:41:08  iter: 1319  total_loss: 0.5515  loss_cls: 0.1119  loss_box_reg: 0.2475  loss_mask: 0.1759  loss_rpn_cls: 0.001106  loss_rpn_loc: 0.0132  time: 0.6587  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:58:01 d2.utils.events]: \u001b[0m eta: 0:40:52  iter: 1339  total_loss: 0.5733  loss_cls: 0.1201  loss_box_reg: 0.2551  loss_mask: 0.1723  loss_rpn_cls: 0.0004715  loss_rpn_loc: 0.01308  time: 0.6588  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:58:15 d2.utils.events]: \u001b[0m eta: 0:40:38  iter: 1359  total_loss: 0.5857  loss_cls: 0.1173  loss_box_reg: 0.2726  loss_mask: 0.1739  loss_rpn_cls: 0.002013  loss_rpn_loc: 0.01328  time: 0.6589  data_time: 0.0087  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:58:28 d2.utils.events]: \u001b[0m eta: 0:40:26  iter: 1379  total_loss: 0.5196  loss_cls: 0.1165  loss_box_reg: 0.2623  loss_mask: 0.1564  loss_rpn_cls: 0.0001365  loss_rpn_loc: 0.01208  time: 0.6592  data_time: 0.0098  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:58:42 d2.utils.events]: \u001b[0m eta: 0:40:16  iter: 1399  total_loss: 0.6041  loss_cls: 0.1179  loss_box_reg: 0.2845  loss_mask: 0.1728  loss_rpn_cls: 0.0007515  loss_rpn_loc: 0.01147  time: 0.6596  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:58:55 d2.utils.events]: \u001b[0m eta: 0:40:07  iter: 1419  total_loss: 0.4731  loss_cls: 0.09121  loss_box_reg: 0.206  loss_mask: 0.1651  loss_rpn_cls: 0.0004624  loss_rpn_loc: 0.01335  time: 0.6597  data_time: 0.0112  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:59:09 d2.utils.events]: \u001b[0m eta: 0:39:51  iter: 1439  total_loss: 0.606  loss_cls: 0.1242  loss_box_reg: 0.2843  loss_mask: 0.1876  loss_rpn_cls: 0.001938  loss_rpn_loc: 0.01415  time: 0.6601  data_time: 0.0082  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:59:22 d2.utils.events]: \u001b[0m eta: 0:39:39  iter: 1459  total_loss: 0.5489  loss_cls: 0.1127  loss_box_reg: 0.2496  loss_mask: 0.1723  loss_rpn_cls: 0.00231  loss_rpn_loc: 0.01445  time: 0.6601  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:59:36 d2.utils.events]: \u001b[0m eta: 0:39:27  iter: 1479  total_loss: 0.5526  loss_cls: 0.1278  loss_box_reg: 0.2277  loss_mask: 0.1846  loss_rpn_cls: 0.001688  loss_rpn_loc: 0.01245  time: 0.6604  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 01:59:49 d2.utils.events]: \u001b[0m eta: 0:39:13  iter: 1499  total_loss: 0.4884  loss_cls: 0.1115  loss_box_reg: 0.1905  loss_mask: 0.1529  loss_rpn_cls: 0.0002799  loss_rpn_loc: 0.009582  time: 0.6604  data_time: 0.0085  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:00:03 d2.utils.events]: \u001b[0m eta: 0:39:00  iter: 1519  total_loss: 0.5872  loss_cls: 0.1342  loss_box_reg: 0.2642  loss_mask: 0.1656  loss_rpn_cls: 0.001295  loss_rpn_loc: 0.01564  time: 0.6607  data_time: 0.0085  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:00:16 d2.utils.events]: \u001b[0m eta: 0:38:46  iter: 1539  total_loss: 0.5539  loss_cls: 0.1208  loss_box_reg: 0.246  loss_mask: 0.1573  loss_rpn_cls: 0.002062  loss_rpn_loc: 0.01001  time: 0.6607  data_time: 0.0082  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:00:29 d2.utils.events]: \u001b[0m eta: 0:38:33  iter: 1559  total_loss: 0.5354  loss_cls: 0.1137  loss_box_reg: 0.2256  loss_mask: 0.1682  loss_rpn_cls: 0.0007713  loss_rpn_loc: 0.01088  time: 0.6607  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:00:43 d2.utils.events]: \u001b[0m eta: 0:38:21  iter: 1579  total_loss: 0.6311  loss_cls: 0.1283  loss_box_reg: 0.2531  loss_mask: 0.1848  loss_rpn_cls: 0.001162  loss_rpn_loc: 0.01486  time: 0.6609  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:00:56 d2.utils.events]: \u001b[0m eta: 0:38:08  iter: 1599  total_loss: 0.5936  loss_cls: 0.1218  loss_box_reg: 0.2682  loss_mask: 0.1937  loss_rpn_cls: 0.0005851  loss_rpn_loc: 0.01299  time: 0.6609  data_time: 0.0067  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:01:09 d2.utils.events]: \u001b[0m eta: 0:37:55  iter: 1619  total_loss: 0.4635  loss_cls: 0.08457  loss_box_reg: 0.1925  loss_mask: 0.1609  loss_rpn_cls: 0.0004961  loss_rpn_loc: 0.01134  time: 0.6608  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:01:23 d2.utils.events]: \u001b[0m eta: 0:37:43  iter: 1639  total_loss: 0.531  loss_cls: 0.1223  loss_box_reg: 0.2349  loss_mask: 0.164  loss_rpn_cls: 0.0008422  loss_rpn_loc: 0.014  time: 0.6610  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:01:36 d2.utils.events]: \u001b[0m eta: 0:37:30  iter: 1659  total_loss: 0.6092  loss_cls: 0.126  loss_box_reg: 0.291  loss_mask: 0.1854  loss_rpn_cls: 0.0009847  loss_rpn_loc: 0.01767  time: 0.6611  data_time: 0.0085  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:01:49 d2.utils.events]: \u001b[0m eta: 0:37:16  iter: 1679  total_loss: 0.5973  loss_cls: 0.1392  loss_box_reg: 0.2646  loss_mask: 0.1756  loss_rpn_cls: 0.00193  loss_rpn_loc: 0.01303  time: 0.6612  data_time: 0.0099  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:02:03 d2.utils.events]: \u001b[0m eta: 0:37:03  iter: 1699  total_loss: 0.5477  loss_cls: 0.1169  loss_box_reg: 0.2537  loss_mask: 0.1672  loss_rpn_cls: 0.0006661  loss_rpn_loc: 0.01359  time: 0.6613  data_time: 0.0109  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:02:16 d2.utils.events]: \u001b[0m eta: 0:36:50  iter: 1719  total_loss: 0.4899  loss_cls: 0.09798  loss_box_reg: 0.2153  loss_mask: 0.1535  loss_rpn_cls: 0.0009174  loss_rpn_loc: 0.009498  time: 0.6615  data_time: 0.0088  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:02:30 d2.utils.events]: \u001b[0m eta: 0:36:37  iter: 1739  total_loss: 0.5126  loss_cls: 0.101  loss_box_reg: 0.2284  loss_mask: 0.1685  loss_rpn_cls: 0.001133  loss_rpn_loc: 0.01461  time: 0.6617  data_time: 0.0093  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:02:43 d2.utils.events]: \u001b[0m eta: 0:36:23  iter: 1759  total_loss: 0.4734  loss_cls: 0.1089  loss_box_reg: 0.2209  loss_mask: 0.1566  loss_rpn_cls: 0.001077  loss_rpn_loc: 0.009926  time: 0.6616  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:02:57 d2.utils.events]: \u001b[0m eta: 0:36:10  iter: 1779  total_loss: 0.5187  loss_cls: 0.1051  loss_box_reg: 0.2464  loss_mask: 0.1621  loss_rpn_cls: 0.0005019  loss_rpn_loc: 0.01334  time: 0.6618  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:03:10 d2.utils.events]: \u001b[0m eta: 0:35:57  iter: 1799  total_loss: 0.5377  loss_cls: 0.1034  loss_box_reg: 0.2284  loss_mask: 0.1635  loss_rpn_cls: 0.001831  loss_rpn_loc: 0.01355  time: 0.6620  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:03:24 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 1819  total_loss: 0.5765  loss_cls: 0.1116  loss_box_reg: 0.2673  loss_mask: 0.1777  loss_rpn_cls: 0.00109  loss_rpn_loc: 0.01391  time: 0.6622  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:03:37 d2.utils.events]: \u001b[0m eta: 0:35:31  iter: 1839  total_loss: 0.4282  loss_cls: 0.0768  loss_box_reg: 0.188  loss_mask: 0.1522  loss_rpn_cls: 0.00123  loss_rpn_loc: 0.009253  time: 0.6622  data_time: 0.0095  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:03:51 d2.utils.events]: \u001b[0m eta: 0:35:17  iter: 1859  total_loss: 0.5667  loss_cls: 0.1167  loss_box_reg: 0.2722  loss_mask: 0.1718  loss_rpn_cls: 0.001884  loss_rpn_loc: 0.01468  time: 0.6623  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:04:04 d2.utils.events]: \u001b[0m eta: 0:35:06  iter: 1879  total_loss: 0.5632  loss_cls: 0.1136  loss_box_reg: 0.2516  loss_mask: 0.1655  loss_rpn_cls: 0.00056  loss_rpn_loc: 0.01153  time: 0.6623  data_time: 0.0061  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:04:17 d2.utils.events]: \u001b[0m eta: 0:34:52  iter: 1899  total_loss: 0.5393  loss_cls: 0.1056  loss_box_reg: 0.2415  loss_mask: 0.178  loss_rpn_cls: 0.001729  loss_rpn_loc: 0.01384  time: 0.6623  data_time: 0.0091  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:04:31 d2.utils.events]: \u001b[0m eta: 0:34:39  iter: 1919  total_loss: 0.5606  loss_cls: 0.09914  loss_box_reg: 0.2472  loss_mask: 0.1666  loss_rpn_cls: 0.001399  loss_rpn_loc: 0.01313  time: 0.6626  data_time: 0.0097  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:04:45 d2.utils.events]: \u001b[0m eta: 0:34:27  iter: 1939  total_loss: 0.525  loss_cls: 0.1052  loss_box_reg: 0.2261  loss_mask: 0.1716  loss_rpn_cls: 0.001019  loss_rpn_loc: 0.01299  time: 0.6628  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:04:58 d2.utils.events]: \u001b[0m eta: 0:34:14  iter: 1959  total_loss: 0.5307  loss_cls: 0.09856  loss_box_reg: 0.2485  loss_mask: 0.1608  loss_rpn_cls: 0.0006067  loss_rpn_loc: 0.01121  time: 0.6631  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:05:12 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 1979  total_loss: 0.5179  loss_cls: 0.09483  loss_box_reg: 0.2324  loss_mask: 0.16  loss_rpn_cls: 0.0004275  loss_rpn_loc: 0.0113  time: 0.6631  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:05:25 d2.utils.events]: \u001b[0m eta: 0:33:47  iter: 1999  total_loss: 0.5292  loss_cls: 0.1098  loss_box_reg: 0.2272  loss_mask: 0.1781  loss_rpn_cls: 0.0009622  loss_rpn_loc: 0.01278  time: 0.6631  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:05:38 d2.utils.events]: \u001b[0m eta: 0:33:33  iter: 2019  total_loss: 0.4798  loss_cls: 0.1054  loss_box_reg: 0.2214  loss_mask: 0.1642  loss_rpn_cls: 0.0003401  loss_rpn_loc: 0.01044  time: 0.6632  data_time: 0.0102  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:05:52 d2.utils.events]: \u001b[0m eta: 0:33:21  iter: 2039  total_loss: 0.5449  loss_cls: 0.1196  loss_box_reg: 0.2364  loss_mask: 0.1662  loss_rpn_cls: 0.0006738  loss_rpn_loc: 0.0124  time: 0.6633  data_time: 0.0094  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:06:05 d2.utils.events]: \u001b[0m eta: 0:33:08  iter: 2059  total_loss: 0.5563  loss_cls: 0.1233  loss_box_reg: 0.2247  loss_mask: 0.1652  loss_rpn_cls: 0.0007872  loss_rpn_loc: 0.01213  time: 0.6632  data_time: 0.0085  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:06:18 d2.utils.events]: \u001b[0m eta: 0:32:54  iter: 2079  total_loss: 0.4846  loss_cls: 0.0985  loss_box_reg: 0.2327  loss_mask: 0.1559  loss_rpn_cls: 0.000999  loss_rpn_loc: 0.01446  time: 0.6632  data_time: 0.0069  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:06:32 d2.utils.events]: \u001b[0m eta: 0:32:41  iter: 2099  total_loss: 0.4883  loss_cls: 0.08892  loss_box_reg: 0.205  loss_mask: 0.1623  loss_rpn_cls: 0.00108  loss_rpn_loc: 0.01053  time: 0.6632  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:06:45 d2.utils.events]: \u001b[0m eta: 0:32:29  iter: 2119  total_loss: 0.4806  loss_cls: 0.0882  loss_box_reg: 0.2218  loss_mask: 0.1616  loss_rpn_cls: 0.0007165  loss_rpn_loc: 0.01052  time: 0.6633  data_time: 0.0069  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:06:59 d2.utils.events]: \u001b[0m eta: 0:32:16  iter: 2139  total_loss: 0.5178  loss_cls: 0.09695  loss_box_reg: 0.271  loss_mask: 0.1622  loss_rpn_cls: 0.0004834  loss_rpn_loc: 0.01422  time: 0.6636  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:07:12 d2.utils.events]: \u001b[0m eta: 0:32:03  iter: 2159  total_loss: 0.4506  loss_cls: 0.09124  loss_box_reg: 0.2019  loss_mask: 0.1506  loss_rpn_cls: 0.0005008  loss_rpn_loc: 0.01068  time: 0.6636  data_time: 0.0066  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:07:25 d2.utils.events]: \u001b[0m eta: 0:31:49  iter: 2179  total_loss: 0.4802  loss_cls: 0.09106  loss_box_reg: 0.2344  loss_mask: 0.1623  loss_rpn_cls: 0.001165  loss_rpn_loc: 0.01115  time: 0.6636  data_time: 0.0088  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:07:39 d2.utils.events]: \u001b[0m eta: 0:31:36  iter: 2199  total_loss: 0.4995  loss_cls: 0.1027  loss_box_reg: 0.2236  loss_mask: 0.1674  loss_rpn_cls: 0.0005705  loss_rpn_loc: 0.01183  time: 0.6637  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:07:52 d2.utils.events]: \u001b[0m eta: 0:31:21  iter: 2219  total_loss: 0.4777  loss_cls: 0.09752  loss_box_reg: 0.2149  loss_mask: 0.1583  loss_rpn_cls: 0.0007907  loss_rpn_loc: 0.01172  time: 0.6637  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:08:06 d2.utils.events]: \u001b[0m eta: 0:31:08  iter: 2239  total_loss: 0.555  loss_cls: 0.1164  loss_box_reg: 0.2686  loss_mask: 0.1674  loss_rpn_cls: 0.0006924  loss_rpn_loc: 0.01155  time: 0.6639  data_time: 0.0101  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:08:19 d2.utils.events]: \u001b[0m eta: 0:30:54  iter: 2259  total_loss: 0.4592  loss_cls: 0.08548  loss_box_reg: 0.2136  loss_mask: 0.1383  loss_rpn_cls: 0.0007109  loss_rpn_loc: 0.01016  time: 0.6638  data_time: 0.0062  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:08:33 d2.utils.events]: \u001b[0m eta: 0:30:42  iter: 2279  total_loss: 0.5092  loss_cls: 0.1115  loss_box_reg: 0.2141  loss_mask: 0.1684  loss_rpn_cls: 0.0007219  loss_rpn_loc: 0.01525  time: 0.6639  data_time: 0.0071  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:08:46 d2.utils.events]: \u001b[0m eta: 0:30:28  iter: 2299  total_loss: 0.4017  loss_cls: 0.07448  loss_box_reg: 0.1779  loss_mask: 0.1462  loss_rpn_cls: 0.0004712  loss_rpn_loc: 0.009915  time: 0.6640  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:09:00 d2.utils.events]: \u001b[0m eta: 0:30:16  iter: 2319  total_loss: 0.4892  loss_cls: 0.09856  loss_box_reg: 0.2182  loss_mask: 0.1653  loss_rpn_cls: 0.0006624  loss_rpn_loc: 0.01029  time: 0.6642  data_time: 0.0084  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:09:13 d2.utils.events]: \u001b[0m eta: 0:30:02  iter: 2339  total_loss: 0.4714  loss_cls: 0.08624  loss_box_reg: 0.2273  loss_mask: 0.1599  loss_rpn_cls: 0.0005078  loss_rpn_loc: 0.01135  time: 0.6641  data_time: 0.0090  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:09:26 d2.utils.events]: \u001b[0m eta: 0:29:49  iter: 2359  total_loss: 0.4562  loss_cls: 0.09189  loss_box_reg: 0.2106  loss_mask: 0.1606  loss_rpn_cls: 0.0005661  loss_rpn_loc: 0.01005  time: 0.6642  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:09:40 d2.utils.events]: \u001b[0m eta: 0:29:35  iter: 2379  total_loss: 0.412  loss_cls: 0.0677  loss_box_reg: 0.1883  loss_mask: 0.1537  loss_rpn_cls: 0.0005044  loss_rpn_loc: 0.01146  time: 0.6641  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:09:53 d2.utils.events]: \u001b[0m eta: 0:29:20  iter: 2399  total_loss: 0.503  loss_cls: 0.1006  loss_box_reg: 0.2372  loss_mask: 0.1575  loss_rpn_cls: 0.001076  loss_rpn_loc: 0.01207  time: 0.6643  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:10:07 d2.utils.events]: \u001b[0m eta: 0:29:05  iter: 2419  total_loss: 0.4489  loss_cls: 0.08038  loss_box_reg: 0.2034  loss_mask: 0.1502  loss_rpn_cls: 0.0007313  loss_rpn_loc: 0.01011  time: 0.6643  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:10:20 d2.utils.events]: \u001b[0m eta: 0:28:52  iter: 2439  total_loss: 0.518  loss_cls: 0.1066  loss_box_reg: 0.2298  loss_mask: 0.1688  loss_rpn_cls: 0.0008843  loss_rpn_loc: 0.01115  time: 0.6643  data_time: 0.0090  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:10:34 d2.utils.events]: \u001b[0m eta: 0:28:39  iter: 2459  total_loss: 0.5258  loss_cls: 0.1109  loss_box_reg: 0.2388  loss_mask: 0.1594  loss_rpn_cls: 0.0008251  loss_rpn_loc: 0.01276  time: 0.6646  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:10:47 d2.utils.events]: \u001b[0m eta: 0:28:25  iter: 2479  total_loss: 0.5085  loss_cls: 0.116  loss_box_reg: 0.2329  loss_mask: 0.1599  loss_rpn_cls: 0.000434  loss_rpn_loc: 0.01373  time: 0.6647  data_time: 0.0087  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:11:01 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 2499  total_loss: 0.5062  loss_cls: 0.08932  loss_box_reg: 0.2282  loss_mask: 0.1578  loss_rpn_cls: 0.0007209  loss_rpn_loc: 0.01251  time: 0.6648  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:11:14 d2.utils.events]: \u001b[0m eta: 0:28:00  iter: 2519  total_loss: 0.5172  loss_cls: 0.1028  loss_box_reg: 0.231  loss_mask: 0.1564  loss_rpn_cls: 0.000502  loss_rpn_loc: 0.01249  time: 0.6649  data_time: 0.0093  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:11:28 d2.utils.events]: \u001b[0m eta: 0:27:47  iter: 2539  total_loss: 0.454  loss_cls: 0.07755  loss_box_reg: 0.2  loss_mask: 0.1517  loss_rpn_cls: 0.0004464  loss_rpn_loc: 0.008903  time: 0.6649  data_time: 0.0080  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:11:42 d2.utils.events]: \u001b[0m eta: 0:27:34  iter: 2559  total_loss: 0.4875  loss_cls: 0.08421  loss_box_reg: 0.2217  loss_mask: 0.1554  loss_rpn_cls: 0.0003996  loss_rpn_loc: 0.009974  time: 0.6651  data_time: 0.0095  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:11:55 d2.utils.events]: \u001b[0m eta: 0:27:20  iter: 2579  total_loss: 0.4443  loss_cls: 0.07806  loss_box_reg: 0.1945  loss_mask: 0.157  loss_rpn_cls: 0.0002973  loss_rpn_loc: 0.009532  time: 0.6651  data_time: 0.0092  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:12:08 d2.utils.events]: \u001b[0m eta: 0:27:06  iter: 2599  total_loss: 0.3967  loss_cls: 0.07452  loss_box_reg: 0.1734  loss_mask: 0.1371  loss_rpn_cls: 0.0002827  loss_rpn_loc: 0.00956  time: 0.6650  data_time: 0.0111  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:12:21 d2.utils.events]: \u001b[0m eta: 0:26:53  iter: 2619  total_loss: 0.4687  loss_cls: 0.08527  loss_box_reg: 0.2093  loss_mask: 0.1499  loss_rpn_cls: 0.0009673  loss_rpn_loc: 0.009391  time: 0.6650  data_time: 0.0080  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:12:35 d2.utils.events]: \u001b[0m eta: 0:26:41  iter: 2639  total_loss: 0.428  loss_cls: 0.08345  loss_box_reg: 0.198  loss_mask: 0.145  loss_rpn_cls: 0.0005503  loss_rpn_loc: 0.01054  time: 0.6653  data_time: 0.0105  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:12:49 d2.utils.events]: \u001b[0m eta: 0:26:28  iter: 2659  total_loss: 0.5039  loss_cls: 0.09717  loss_box_reg: 0.216  loss_mask: 0.1552  loss_rpn_cls: 0.0009556  loss_rpn_loc: 0.01172  time: 0.6654  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:13:03 d2.utils.events]: \u001b[0m eta: 0:26:14  iter: 2679  total_loss: 0.4571  loss_cls: 0.09422  loss_box_reg: 0.1915  loss_mask: 0.1503  loss_rpn_cls: 0.0005933  loss_rpn_loc: 0.01063  time: 0.6656  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:13:17 d2.utils.events]: \u001b[0m eta: 0:26:00  iter: 2699  total_loss: 0.4791  loss_cls: 0.1033  loss_box_reg: 0.2051  loss_mask: 0.1518  loss_rpn_cls: 0.0002305  loss_rpn_loc: 0.01187  time: 0.6657  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:13:30 d2.utils.events]: \u001b[0m eta: 0:25:47  iter: 2719  total_loss: 0.5036  loss_cls: 0.08544  loss_box_reg: 0.233  loss_mask: 0.1603  loss_rpn_cls: 0.000721  loss_rpn_loc: 0.01194  time: 0.6658  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:13:43 d2.utils.events]: \u001b[0m eta: 0:25:32  iter: 2739  total_loss: 0.4851  loss_cls: 0.08772  loss_box_reg: 0.208  loss_mask: 0.147  loss_rpn_cls: 0.0006155  loss_rpn_loc: 0.01153  time: 0.6658  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:13:57 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 2759  total_loss: 0.5224  loss_cls: 0.09451  loss_box_reg: 0.2334  loss_mask: 0.1653  loss_rpn_cls: 0.0004787  loss_rpn_loc: 0.0134  time: 0.6659  data_time: 0.0091  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:14:10 d2.utils.events]: \u001b[0m eta: 0:25:06  iter: 2779  total_loss: 0.4873  loss_cls: 0.09994  loss_box_reg: 0.2066  loss_mask: 0.1474  loss_rpn_cls: 0.00032  loss_rpn_loc: 0.01196  time: 0.6659  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:14:24 d2.utils.events]: \u001b[0m eta: 0:24:52  iter: 2799  total_loss: 0.4731  loss_cls: 0.09355  loss_box_reg: 0.2211  loss_mask: 0.1608  loss_rpn_cls: 0.000537  loss_rpn_loc: 0.01024  time: 0.6659  data_time: 0.0069  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:14:37 d2.utils.events]: \u001b[0m eta: 0:24:38  iter: 2819  total_loss: 0.4158  loss_cls: 0.07359  loss_box_reg: 0.1965  loss_mask: 0.1387  loss_rpn_cls: 0.0005459  loss_rpn_loc: 0.009276  time: 0.6659  data_time: 0.0105  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:14:51 d2.utils.events]: \u001b[0m eta: 0:24:25  iter: 2839  total_loss: 0.5087  loss_cls: 0.08647  loss_box_reg: 0.2585  loss_mask: 0.1577  loss_rpn_cls: 0.0005201  loss_rpn_loc: 0.01199  time: 0.6660  data_time: 0.0089  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:15:04 d2.utils.events]: \u001b[0m eta: 0:24:12  iter: 2859  total_loss: 0.4898  loss_cls: 0.0912  loss_box_reg: 0.2413  loss_mask: 0.1615  loss_rpn_cls: 0.0005097  loss_rpn_loc: 0.01269  time: 0.6660  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:15:18 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 2879  total_loss: 0.4596  loss_cls: 0.08779  loss_box_reg: 0.2137  loss_mask: 0.1477  loss_rpn_cls: 0.0004431  loss_rpn_loc: 0.01258  time: 0.6662  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:15:31 d2.utils.events]: \u001b[0m eta: 0:23:46  iter: 2899  total_loss: 0.4199  loss_cls: 0.07686  loss_box_reg: 0.1851  loss_mask: 0.1556  loss_rpn_cls: 0.0005312  loss_rpn_loc: 0.009416  time: 0.6662  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:15:45 d2.utils.events]: \u001b[0m eta: 0:23:31  iter: 2919  total_loss: 0.4457  loss_cls: 0.0976  loss_box_reg: 0.1842  loss_mask: 0.157  loss_rpn_cls: 0.0002479  loss_rpn_loc: 0.008841  time: 0.6662  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:15:58 d2.utils.events]: \u001b[0m eta: 0:23:17  iter: 2939  total_loss: 0.4947  loss_cls: 0.1008  loss_box_reg: 0.2317  loss_mask: 0.1572  loss_rpn_cls: 0.0003201  loss_rpn_loc: 0.01259  time: 0.6662  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:16:12 d2.utils.events]: \u001b[0m eta: 0:23:04  iter: 2959  total_loss: 0.5536  loss_cls: 0.1043  loss_box_reg: 0.2649  loss_mask: 0.1599  loss_rpn_cls: 0.0008849  loss_rpn_loc: 0.01428  time: 0.6664  data_time: 0.0075  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:16:25 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 2979  total_loss: 0.4931  loss_cls: 0.1015  loss_box_reg: 0.2282  loss_mask: 0.1514  loss_rpn_cls: 0.0009759  loss_rpn_loc: 0.01131  time: 0.6665  data_time: 0.0082  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:16:39 d2.utils.events]: \u001b[0m eta: 0:22:37  iter: 2999  total_loss: 0.3989  loss_cls: 0.07281  loss_box_reg: 0.1721  loss_mask: 0.1457  loss_rpn_cls: 0.000415  loss_rpn_loc: 0.008503  time: 0.6665  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:16:52 d2.utils.events]: \u001b[0m eta: 0:22:22  iter: 3019  total_loss: 0.4577  loss_cls: 0.08091  loss_box_reg: 0.213  loss_mask: 0.147  loss_rpn_cls: 0.0004037  loss_rpn_loc: 0.01236  time: 0.6665  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:17:06 d2.utils.events]: \u001b[0m eta: 0:22:08  iter: 3039  total_loss: 0.4428  loss_cls: 0.08949  loss_box_reg: 0.1913  loss_mask: 0.1539  loss_rpn_cls: 0.0002319  loss_rpn_loc: 0.0111  time: 0.6666  data_time: 0.0090  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:17:19 d2.utils.events]: \u001b[0m eta: 0:21:57  iter: 3059  total_loss: 0.4609  loss_cls: 0.08162  loss_box_reg: 0.2117  loss_mask: 0.149  loss_rpn_cls: 0.0002027  loss_rpn_loc: 0.01009  time: 0.6667  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:17:33 d2.utils.events]: \u001b[0m eta: 0:21:43  iter: 3079  total_loss: 0.442  loss_cls: 0.07847  loss_box_reg: 0.1953  loss_mask: 0.1585  loss_rpn_cls: 0.0006082  loss_rpn_loc: 0.0119  time: 0.6667  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:17:46 d2.utils.events]: \u001b[0m eta: 0:21:30  iter: 3099  total_loss: 0.4342  loss_cls: 0.08075  loss_box_reg: 0.1983  loss_mask: 0.1518  loss_rpn_cls: 0.0003974  loss_rpn_loc: 0.008315  time: 0.6668  data_time: 0.0089  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:18:00 d2.utils.events]: \u001b[0m eta: 0:21:16  iter: 3119  total_loss: 0.4344  loss_cls: 0.08572  loss_box_reg: 0.1855  loss_mask: 0.15  loss_rpn_cls: 0.0003234  loss_rpn_loc: 0.01146  time: 0.6668  data_time: 0.0103  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:18:13 d2.utils.events]: \u001b[0m eta: 0:21:02  iter: 3139  total_loss: 0.482  loss_cls: 0.08965  loss_box_reg: 0.2132  loss_mask: 0.166  loss_rpn_cls: 0.002302  loss_rpn_loc: 0.01067  time: 0.6667  data_time: 0.0082  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:18:26 d2.utils.events]: \u001b[0m eta: 0:20:48  iter: 3159  total_loss: 0.4734  loss_cls: 0.08852  loss_box_reg: 0.2094  loss_mask: 0.1514  loss_rpn_cls: 0.0005276  loss_rpn_loc: 0.01207  time: 0.6667  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:18:40 d2.utils.events]: \u001b[0m eta: 0:20:35  iter: 3179  total_loss: 0.4492  loss_cls: 0.08412  loss_box_reg: 0.2052  loss_mask: 0.1529  loss_rpn_cls: 0.0004114  loss_rpn_loc: 0.009502  time: 0.6668  data_time: 0.0075  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:18:53 d2.utils.events]: \u001b[0m eta: 0:20:21  iter: 3199  total_loss: 0.4282  loss_cls: 0.07666  loss_box_reg: 0.1943  loss_mask: 0.1544  loss_rpn_cls: 0.0002015  loss_rpn_loc: 0.008762  time: 0.6669  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:19:07 d2.utils.events]: \u001b[0m eta: 0:20:08  iter: 3219  total_loss: 0.4468  loss_cls: 0.07969  loss_box_reg: 0.1983  loss_mask: 0.15  loss_rpn_cls: 0.0003457  loss_rpn_loc: 0.01048  time: 0.6668  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:19:20 d2.utils.events]: \u001b[0m eta: 0:19:55  iter: 3239  total_loss: 0.4081  loss_cls: 0.07134  loss_box_reg: 0.1827  loss_mask: 0.1495  loss_rpn_cls: 0.0002741  loss_rpn_loc: 0.009527  time: 0.6669  data_time: 0.0090  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:19:34 d2.utils.events]: \u001b[0m eta: 0:19:42  iter: 3259  total_loss: 0.4659  loss_cls: 0.09697  loss_box_reg: 0.2189  loss_mask: 0.1462  loss_rpn_cls: 0.0004743  loss_rpn_loc: 0.0121  time: 0.6670  data_time: 0.0087  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:19:48 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 3279  total_loss: 0.5041  loss_cls: 0.1014  loss_box_reg: 0.2123  loss_mask: 0.156  loss_rpn_cls: 0.0007851  loss_rpn_loc: 0.01338  time: 0.6671  data_time: 0.0087  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:20:01 d2.utils.events]: \u001b[0m eta: 0:19:14  iter: 3299  total_loss: 0.5254  loss_cls: 0.09662  loss_box_reg: 0.2315  loss_mask: 0.1585  loss_rpn_cls: 0.0009021  loss_rpn_loc: 0.01456  time: 0.6672  data_time: 0.0100  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:20:15 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 3319  total_loss: 0.4366  loss_cls: 0.08588  loss_box_reg: 0.2093  loss_mask: 0.1417  loss_rpn_cls: 0.0004975  loss_rpn_loc: 0.01064  time: 0.6672  data_time: 0.0075  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:20:28 d2.utils.events]: \u001b[0m eta: 0:18:47  iter: 3339  total_loss: 0.4291  loss_cls: 0.08196  loss_box_reg: 0.1905  loss_mask: 0.1449  loss_rpn_cls: 0.001329  loss_rpn_loc: 0.01062  time: 0.6672  data_time: 0.0087  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:20:41 d2.utils.events]: \u001b[0m eta: 0:18:33  iter: 3359  total_loss: 0.4066  loss_cls: 0.08548  loss_box_reg: 0.1672  loss_mask: 0.1476  loss_rpn_cls: 0.0008714  loss_rpn_loc: 0.008412  time: 0.6672  data_time: 0.0083  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:20:54 d2.utils.events]: \u001b[0m eta: 0:18:20  iter: 3379  total_loss: 0.4567  loss_cls: 0.07888  loss_box_reg: 0.2086  loss_mask: 0.1533  loss_rpn_cls: 0.0004799  loss_rpn_loc: 0.01036  time: 0.6671  data_time: 0.0082  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:21:08 d2.utils.events]: \u001b[0m eta: 0:18:07  iter: 3399  total_loss: 0.4545  loss_cls: 0.07981  loss_box_reg: 0.2152  loss_mask: 0.1458  loss_rpn_cls: 0.0004187  loss_rpn_loc: 0.009917  time: 0.6671  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:21:21 d2.utils.events]: \u001b[0m eta: 0:17:54  iter: 3419  total_loss: 0.4714  loss_cls: 0.08678  loss_box_reg: 0.2193  loss_mask: 0.1546  loss_rpn_cls: 0.0004093  loss_rpn_loc: 0.01359  time: 0.6672  data_time: 0.0092  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:21:35 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 3439  total_loss: 0.4364  loss_cls: 0.07771  loss_box_reg: 0.2009  loss_mask: 0.1374  loss_rpn_cls: 0.0004627  loss_rpn_loc: 0.01063  time: 0.6674  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:21:48 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 3459  total_loss: 0.431  loss_cls: 0.08031  loss_box_reg: 0.1801  loss_mask: 0.1458  loss_rpn_cls: 0.0001855  loss_rpn_loc: 0.00915  time: 0.6673  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:22:02 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 3479  total_loss: 0.47  loss_cls: 0.08284  loss_box_reg: 0.2069  loss_mask: 0.1503  loss_rpn_cls: 0.0002059  loss_rpn_loc: 0.01073  time: 0.6673  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:22:15 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 3499  total_loss: 0.4248  loss_cls: 0.0716  loss_box_reg: 0.2035  loss_mask: 0.1434  loss_rpn_cls: 0.0003145  loss_rpn_loc: 0.009953  time: 0.6674  data_time: 0.0071  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:22:29 d2.utils.events]: \u001b[0m eta: 0:16:45  iter: 3519  total_loss: 0.4162  loss_cls: 0.06554  loss_box_reg: 0.1727  loss_mask: 0.1528  loss_rpn_cls: 0.0004737  loss_rpn_loc: 0.00812  time: 0.6673  data_time: 0.0067  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:22:42 d2.utils.events]: \u001b[0m eta: 0:16:31  iter: 3539  total_loss: 0.4219  loss_cls: 0.08355  loss_box_reg: 0.1898  loss_mask: 0.1484  loss_rpn_cls: 0.0002414  loss_rpn_loc: 0.0102  time: 0.6672  data_time: 0.0085  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:22:55 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 3559  total_loss: 0.4515  loss_cls: 0.08352  loss_box_reg: 0.1853  loss_mask: 0.1492  loss_rpn_cls: 0.0003622  loss_rpn_loc: 0.01048  time: 0.6672  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:23:08 d2.utils.events]: \u001b[0m eta: 0:16:04  iter: 3579  total_loss: 0.443  loss_cls: 0.08577  loss_box_reg: 0.1957  loss_mask: 0.1507  loss_rpn_cls: 0.000451  loss_rpn_loc: 0.009254  time: 0.6673  data_time: 0.0093  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:23:22 d2.utils.events]: \u001b[0m eta: 0:15:51  iter: 3599  total_loss: 0.4368  loss_cls: 0.07863  loss_box_reg: 0.2005  loss_mask: 0.1519  loss_rpn_cls: 0.0003094  loss_rpn_loc: 0.01002  time: 0.6673  data_time: 0.0102  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:23:35 d2.utils.events]: \u001b[0m eta: 0:15:37  iter: 3619  total_loss: 0.3748  loss_cls: 0.06946  loss_box_reg: 0.1601  loss_mask: 0.131  loss_rpn_cls: 0.0003989  loss_rpn_loc: 0.008155  time: 0.6673  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:23:49 d2.utils.events]: \u001b[0m eta: 0:15:23  iter: 3639  total_loss: 0.3862  loss_cls: 0.0675  loss_box_reg: 0.1765  loss_mask: 0.1379  loss_rpn_cls: 0.000262  loss_rpn_loc: 0.01036  time: 0.6673  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:24:02 d2.utils.events]: \u001b[0m eta: 0:15:09  iter: 3659  total_loss: 0.3918  loss_cls: 0.06612  loss_box_reg: 0.1771  loss_mask: 0.1446  loss_rpn_cls: 0.0003142  loss_rpn_loc: 0.01087  time: 0.6673  data_time: 0.0091  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:24:16 d2.utils.events]: \u001b[0m eta: 0:14:55  iter: 3679  total_loss: 0.4218  loss_cls: 0.07533  loss_box_reg: 0.1767  loss_mask: 0.1422  loss_rpn_cls: 0.0003641  loss_rpn_loc: 0.0113  time: 0.6674  data_time: 0.0066  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:24:29 d2.utils.events]: \u001b[0m eta: 0:14:42  iter: 3699  total_loss: 0.4516  loss_cls: 0.0729  loss_box_reg: 0.1963  loss_mask: 0.146  loss_rpn_cls: 0.0003111  loss_rpn_loc: 0.01023  time: 0.6674  data_time: 0.0085  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:24:43 d2.utils.events]: \u001b[0m eta: 0:14:28  iter: 3719  total_loss: 0.4493  loss_cls: 0.08193  loss_box_reg: 0.2077  loss_mask: 0.1557  loss_rpn_cls: 0.0006742  loss_rpn_loc: 0.01101  time: 0.6675  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:24:57 d2.utils.events]: \u001b[0m eta: 0:14:15  iter: 3739  total_loss: 0.5094  loss_cls: 0.09303  loss_box_reg: 0.2322  loss_mask: 0.1554  loss_rpn_cls: 0.0004643  loss_rpn_loc: 0.01386  time: 0.6676  data_time: 0.0109  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:25:10 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 3759  total_loss: 0.4368  loss_cls: 0.08117  loss_box_reg: 0.1829  loss_mask: 0.1422  loss_rpn_cls: 0.0004438  loss_rpn_loc: 0.01285  time: 0.6677  data_time: 0.0080  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:25:24 d2.utils.events]: \u001b[0m eta: 0:13:48  iter: 3779  total_loss: 0.3873  loss_cls: 0.06909  loss_box_reg: 0.1538  loss_mask: 0.1441  loss_rpn_cls: 0.0001825  loss_rpn_loc: 0.008368  time: 0.6677  data_time: 0.0093  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:25:37 d2.utils.events]: \u001b[0m eta: 0:13:35  iter: 3799  total_loss: 0.4178  loss_cls: 0.08116  loss_box_reg: 0.2  loss_mask: 0.1495  loss_rpn_cls: 0.0003874  loss_rpn_loc: 0.01126  time: 0.6678  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:25:50 d2.utils.events]: \u001b[0m eta: 0:13:21  iter: 3819  total_loss: 0.4705  loss_cls: 0.08659  loss_box_reg: 0.1922  loss_mask: 0.1611  loss_rpn_cls: 0.0006478  loss_rpn_loc: 0.01177  time: 0.6677  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:26:04 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 3839  total_loss: 0.3907  loss_cls: 0.08242  loss_box_reg: 0.1695  loss_mask: 0.1323  loss_rpn_cls: 0.0002393  loss_rpn_loc: 0.0104  time: 0.6677  data_time: 0.0071  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:26:17 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 3859  total_loss: 0.3862  loss_cls: 0.06983  loss_box_reg: 0.1655  loss_mask: 0.1314  loss_rpn_cls: 0.0003055  loss_rpn_loc: 0.009067  time: 0.6677  data_time: 0.0077  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:26:30 d2.utils.events]: \u001b[0m eta: 0:12:40  iter: 3879  total_loss: 0.3818  loss_cls: 0.06784  loss_box_reg: 0.167  loss_mask: 0.1417  loss_rpn_cls: 0.0005042  loss_rpn_loc: 0.01108  time: 0.6677  data_time: 0.0082  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:26:44 d2.utils.events]: \u001b[0m eta: 0:12:26  iter: 3899  total_loss: 0.43  loss_cls: 0.07987  loss_box_reg: 0.1818  loss_mask: 0.139  loss_rpn_cls: 0.0003613  loss_rpn_loc: 0.009285  time: 0.6678  data_time: 0.0084  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:26:58 d2.utils.events]: \u001b[0m eta: 0:12:13  iter: 3919  total_loss: 0.4279  loss_cls: 0.07983  loss_box_reg: 0.1922  loss_mask: 0.1501  loss_rpn_cls: 0.0002739  loss_rpn_loc: 0.009416  time: 0.6678  data_time: 0.0095  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:27:10 d2.utils.events]: \u001b[0m eta: 0:11:59  iter: 3939  total_loss: 0.3667  loss_cls: 0.06228  loss_box_reg: 0.1492  loss_mask: 0.1337  loss_rpn_cls: 0.0001699  loss_rpn_loc: 0.007647  time: 0.6677  data_time: 0.0105  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:27:24 d2.utils.events]: \u001b[0m eta: 0:11:45  iter: 3959  total_loss: 0.4187  loss_cls: 0.08248  loss_box_reg: 0.1789  loss_mask: 0.1466  loss_rpn_cls: 0.0003168  loss_rpn_loc: 0.008376  time: 0.6678  data_time: 0.0102  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:27:38 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 3979  total_loss: 0.4143  loss_cls: 0.09564  loss_box_reg: 0.1656  loss_mask: 0.1386  loss_rpn_cls: 0.0004802  loss_rpn_loc: 0.01054  time: 0.6678  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:27:51 d2.utils.events]: \u001b[0m eta: 0:11:18  iter: 3999  total_loss: 0.5195  loss_cls: 0.09896  loss_box_reg: 0.2383  loss_mask: 0.1611  loss_rpn_cls: 0.000359  loss_rpn_loc: 0.01427  time: 0.6679  data_time: 0.0069  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:28:05 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 4019  total_loss: 0.4287  loss_cls: 0.08032  loss_box_reg: 0.1665  loss_mask: 0.148  loss_rpn_cls: 0.0007202  loss_rpn_loc: 0.01107  time: 0.6679  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:28:18 d2.utils.events]: \u001b[0m eta: 0:10:50  iter: 4039  total_loss: 0.4113  loss_cls: 0.06985  loss_box_reg: 0.1737  loss_mask: 0.1495  loss_rpn_cls: 0.0002308  loss_rpn_loc: 0.008556  time: 0.6679  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:28:32 d2.utils.events]: \u001b[0m eta: 0:10:37  iter: 4059  total_loss: 0.4379  loss_cls: 0.08011  loss_box_reg: 0.2025  loss_mask: 0.1517  loss_rpn_cls: 0.0002335  loss_rpn_loc: 0.01072  time: 0.6680  data_time: 0.0120  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:28:45 d2.utils.events]: \u001b[0m eta: 0:10:24  iter: 4079  total_loss: 0.3966  loss_cls: 0.07133  loss_box_reg: 0.1862  loss_mask: 0.141  loss_rpn_cls: 0.0003328  loss_rpn_loc: 0.009733  time: 0.6680  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:28:59 d2.utils.events]: \u001b[0m eta: 0:10:09  iter: 4099  total_loss: 0.4197  loss_cls: 0.07163  loss_box_reg: 0.2009  loss_mask: 0.1381  loss_rpn_cls: 0.0005202  loss_rpn_loc: 0.01039  time: 0.6680  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:29:12 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 4119  total_loss: 0.4098  loss_cls: 0.07257  loss_box_reg: 0.1828  loss_mask: 0.1372  loss_rpn_cls: 0.0002393  loss_rpn_loc: 0.009651  time: 0.6681  data_time: 0.0068  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:29:26 d2.utils.events]: \u001b[0m eta: 0:09:43  iter: 4139  total_loss: 0.4353  loss_cls: 0.08389  loss_box_reg: 0.1815  loss_mask: 0.1463  loss_rpn_cls: 0.0005762  loss_rpn_loc: 0.009971  time: 0.6681  data_time: 0.0084  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:29:40 d2.utils.events]: \u001b[0m eta: 0:09:30  iter: 4159  total_loss: 0.4876  loss_cls: 0.09804  loss_box_reg: 0.2155  loss_mask: 0.1574  loss_rpn_cls: 0.0002953  loss_rpn_loc: 0.01412  time: 0.6682  data_time: 0.0092  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:29:53 d2.utils.events]: \u001b[0m eta: 0:09:16  iter: 4179  total_loss: 0.3296  loss_cls: 0.06283  loss_box_reg: 0.1352  loss_mask: 0.1359  loss_rpn_cls: 0.0002126  loss_rpn_loc: 0.008654  time: 0.6682  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:30:06 d2.utils.events]: \u001b[0m eta: 0:09:02  iter: 4199  total_loss: 0.3893  loss_cls: 0.06456  loss_box_reg: 0.1604  loss_mask: 0.1331  loss_rpn_cls: 0.000219  loss_rpn_loc: 0.01039  time: 0.6682  data_time: 0.0080  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:30:20 d2.utils.events]: \u001b[0m eta: 0:08:49  iter: 4219  total_loss: 0.4947  loss_cls: 0.08345  loss_box_reg: 0.2141  loss_mask: 0.1485  loss_rpn_cls: 0.0002266  loss_rpn_loc: 0.01235  time: 0.6683  data_time: 0.0071  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:30:34 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 4239  total_loss: 0.4129  loss_cls: 0.08604  loss_box_reg: 0.1858  loss_mask: 0.1484  loss_rpn_cls: 0.000493  loss_rpn_loc: 0.008827  time: 0.6683  data_time: 0.0062  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:30:47 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 4259  total_loss: 0.4386  loss_cls: 0.07453  loss_box_reg: 0.2051  loss_mask: 0.1395  loss_rpn_cls: 0.0003629  loss_rpn_loc: 0.01066  time: 0.6684  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:31:01 d2.utils.events]: \u001b[0m eta: 0:08:08  iter: 4279  total_loss: 0.3954  loss_cls: 0.07508  loss_box_reg: 0.1811  loss_mask: 0.1413  loss_rpn_cls: 0.0003448  loss_rpn_loc: 0.01147  time: 0.6684  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:31:15 d2.utils.events]: \u001b[0m eta: 0:07:54  iter: 4299  total_loss: 0.4093  loss_cls: 0.08737  loss_box_reg: 0.1684  loss_mask: 0.1378  loss_rpn_cls: 0.0002426  loss_rpn_loc: 0.008263  time: 0.6686  data_time: 0.0095  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:31:28 d2.utils.events]: \u001b[0m eta: 0:07:41  iter: 4319  total_loss: 0.4464  loss_cls: 0.08724  loss_box_reg: 0.1956  loss_mask: 0.1481  loss_rpn_cls: 0.0003342  loss_rpn_loc: 0.01201  time: 0.6686  data_time: 0.0103  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:31:42 d2.utils.events]: \u001b[0m eta: 0:07:27  iter: 4339  total_loss: 0.3849  loss_cls: 0.07346  loss_box_reg: 0.1729  loss_mask: 0.1458  loss_rpn_cls: 0.0002897  loss_rpn_loc: 0.00911  time: 0.6686  data_time: 0.0073  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:31:55 d2.utils.events]: \u001b[0m eta: 0:07:14  iter: 4359  total_loss: 0.4329  loss_cls: 0.08318  loss_box_reg: 0.1843  loss_mask: 0.14  loss_rpn_cls: 0.0003273  loss_rpn_loc: 0.01004  time: 0.6686  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:32:08 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 4379  total_loss: 0.3912  loss_cls: 0.07143  loss_box_reg: 0.1782  loss_mask: 0.1291  loss_rpn_cls: 0.0001406  loss_rpn_loc: 0.008861  time: 0.6686  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:32:22 d2.utils.events]: \u001b[0m eta: 0:06:47  iter: 4399  total_loss: 0.3474  loss_cls: 0.06133  loss_box_reg: 0.1606  loss_mask: 0.1333  loss_rpn_cls: 0.0003011  loss_rpn_loc: 0.009999  time: 0.6685  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:32:35 d2.utils.events]: \u001b[0m eta: 0:06:33  iter: 4419  total_loss: 0.4046  loss_cls: 0.07076  loss_box_reg: 0.178  loss_mask: 0.1456  loss_rpn_cls: 0.0002506  loss_rpn_loc: 0.008715  time: 0.6685  data_time: 0.0088  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:32:48 d2.utils.events]: \u001b[0m eta: 0:06:19  iter: 4439  total_loss: 0.4345  loss_cls: 0.08527  loss_box_reg: 0.1921  loss_mask: 0.1443  loss_rpn_cls: 0.0005497  loss_rpn_loc: 0.0106  time: 0.6685  data_time: 0.0069  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:33:02 d2.utils.events]: \u001b[0m eta: 0:06:06  iter: 4459  total_loss: 0.4039  loss_cls: 0.07185  loss_box_reg: 0.1747  loss_mask: 0.1483  loss_rpn_cls: 0.0003454  loss_rpn_loc: 0.009606  time: 0.6686  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:33:16 d2.utils.events]: \u001b[0m eta: 0:05:52  iter: 4479  total_loss: 0.3712  loss_cls: 0.06491  loss_box_reg: 0.1588  loss_mask: 0.1389  loss_rpn_cls: 0.0001333  loss_rpn_loc: 0.00748  time: 0.6687  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:33:29 d2.utils.events]: \u001b[0m eta: 0:05:39  iter: 4499  total_loss: 0.3595  loss_cls: 0.07109  loss_box_reg: 0.1606  loss_mask: 0.132  loss_rpn_cls: 0.0002289  loss_rpn_loc: 0.008399  time: 0.6687  data_time: 0.0084  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:33:43 d2.utils.events]: \u001b[0m eta: 0:05:25  iter: 4519  total_loss: 0.4096  loss_cls: 0.06853  loss_box_reg: 0.1663  loss_mask: 0.145  loss_rpn_cls: 0.0004327  loss_rpn_loc: 0.009856  time: 0.6687  data_time: 0.0080  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:33:56 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 4539  total_loss: 0.353  loss_cls: 0.06392  loss_box_reg: 0.1402  loss_mask: 0.1342  loss_rpn_cls: 0.0005207  loss_rpn_loc: 0.008204  time: 0.6687  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:34:09 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 4559  total_loss: 0.4017  loss_cls: 0.07228  loss_box_reg: 0.1757  loss_mask: 0.1436  loss_rpn_cls: 0.0003701  loss_rpn_loc: 0.01055  time: 0.6687  data_time: 0.0089  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:34:23 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 4579  total_loss: 0.4142  loss_cls: 0.07215  loss_box_reg: 0.1904  loss_mask: 0.1372  loss_rpn_cls: 0.0003286  loss_rpn_loc: 0.01182  time: 0.6687  data_time: 0.0083  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:34:36 d2.utils.events]: \u001b[0m eta: 0:04:31  iter: 4599  total_loss: 0.4313  loss_cls: 0.07747  loss_box_reg: 0.1912  loss_mask: 0.1375  loss_rpn_cls: 0.0002687  loss_rpn_loc: 0.009719  time: 0.6688  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:34:49 d2.utils.events]: \u001b[0m eta: 0:04:17  iter: 4619  total_loss: 0.3485  loss_cls: 0.06909  loss_box_reg: 0.1473  loss_mask: 0.1274  loss_rpn_cls: 0.0001827  loss_rpn_loc: 0.007471  time: 0.6687  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:35:03 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 4639  total_loss: 0.358  loss_cls: 0.06755  loss_box_reg: 0.1482  loss_mask: 0.1362  loss_rpn_cls: 0.0002238  loss_rpn_loc: 0.007062  time: 0.6687  data_time: 0.0127  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:35:16 d2.utils.events]: \u001b[0m eta: 0:03:51  iter: 4659  total_loss: 0.4183  loss_cls: 0.07172  loss_box_reg: 0.1873  loss_mask: 0.1355  loss_rpn_cls: 0.0002239  loss_rpn_loc: 0.01172  time: 0.6687  data_time: 0.0072  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:35:30 d2.utils.events]: \u001b[0m eta: 0:03:37  iter: 4679  total_loss: 0.3957  loss_cls: 0.06371  loss_box_reg: 0.1759  loss_mask: 0.1301  loss_rpn_cls: 0.0002321  loss_rpn_loc: 0.009746  time: 0.6687  data_time: 0.0074  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:35:43 d2.utils.events]: \u001b[0m eta: 0:03:23  iter: 4699  total_loss: 0.3743  loss_cls: 0.06218  loss_box_reg: 0.156  loss_mask: 0.1306  loss_rpn_cls: 0.0001512  loss_rpn_loc: 0.01067  time: 0.6687  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:35:57 d2.utils.events]: \u001b[0m eta: 0:03:10  iter: 4719  total_loss: 0.369  loss_cls: 0.06085  loss_box_reg: 0.1496  loss_mask: 0.1395  loss_rpn_cls: 0.0001403  loss_rpn_loc: 0.008974  time: 0.6688  data_time: 0.0076  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:36:10 d2.utils.events]: \u001b[0m eta: 0:02:56  iter: 4739  total_loss: 0.3888  loss_cls: 0.07535  loss_box_reg: 0.1614  loss_mask: 0.1409  loss_rpn_cls: 0.0003138  loss_rpn_loc: 0.009392  time: 0.6688  data_time: 0.0071  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:36:24 d2.utils.events]: \u001b[0m eta: 0:02:42  iter: 4759  total_loss: 0.3593  loss_cls: 0.06053  loss_box_reg: 0.1616  loss_mask: 0.1338  loss_rpn_cls: 0.0001957  loss_rpn_loc: 0.009018  time: 0.6689  data_time: 0.0075  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:36:38 d2.utils.events]: \u001b[0m eta: 0:02:29  iter: 4779  total_loss: 0.3878  loss_cls: 0.06864  loss_box_reg: 0.1693  loss_mask: 0.1344  loss_rpn_cls: 0.0001551  loss_rpn_loc: 0.01017  time: 0.6689  data_time: 0.0088  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:36:51 d2.utils.events]: \u001b[0m eta: 0:02:15  iter: 4799  total_loss: 0.4006  loss_cls: 0.07874  loss_box_reg: 0.1756  loss_mask: 0.1359  loss_rpn_cls: 0.0002017  loss_rpn_loc: 0.01158  time: 0.6689  data_time: 0.0078  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:37:05 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 4819  total_loss: 0.4  loss_cls: 0.07039  loss_box_reg: 0.1791  loss_mask: 0.1416  loss_rpn_cls: 0.0002148  loss_rpn_loc: 0.00865  time: 0.6690  data_time: 0.0069  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:37:18 d2.utils.events]: \u001b[0m eta: 0:01:48  iter: 4839  total_loss: 0.4318  loss_cls: 0.07746  loss_box_reg: 0.1928  loss_mask: 0.1471  loss_rpn_cls: 0.000588  loss_rpn_loc: 0.01268  time: 0.6690  data_time: 0.0065  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:37:32 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 4859  total_loss: 0.3579  loss_cls: 0.06244  loss_box_reg: 0.1553  loss_mask: 0.1391  loss_rpn_cls: 0.0001435  loss_rpn_loc: 0.006837  time: 0.6690  data_time: 0.0082  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:37:46 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 4879  total_loss: 0.4106  loss_cls: 0.06883  loss_box_reg: 0.1886  loss_mask: 0.1398  loss_rpn_cls: 0.0001679  loss_rpn_loc: 0.009909  time: 0.6691  data_time: 0.0086  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:37:59 d2.utils.events]: \u001b[0m eta: 0:01:08  iter: 4899  total_loss: 0.3975  loss_cls: 0.07372  loss_box_reg: 0.1643  loss_mask: 0.1346  loss_rpn_cls: 0.0002415  loss_rpn_loc: 0.01006  time: 0.6692  data_time: 0.0102  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:38:13 d2.utils.events]: \u001b[0m eta: 0:00:54  iter: 4919  total_loss: 0.3322  loss_cls: 0.05861  loss_box_reg: 0.133  loss_mask: 0.138  loss_rpn_cls: 0.0001801  loss_rpn_loc: 0.008181  time: 0.6692  data_time: 0.0081  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:38:26 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 4939  total_loss: 0.3913  loss_cls: 0.06548  loss_box_reg: 0.1714  loss_mask: 0.1452  loss_rpn_cls: 0.0009598  loss_rpn_loc: 0.007486  time: 0.6692  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:38:40 d2.utils.events]: \u001b[0m eta: 0:00:27  iter: 4959  total_loss: 0.4097  loss_cls: 0.07308  loss_box_reg: 0.1879  loss_mask: 0.138  loss_rpn_cls: 0.0003739  loss_rpn_loc: 0.01024  time: 0.6693  data_time: 0.0070  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:38:54 d2.utils.events]: \u001b[0m eta: 0:00:13  iter: 4979  total_loss: 0.412  loss_cls: 0.07581  loss_box_reg: 0.1874  loss_mask: 0.1403  loss_rpn_cls: 0.0007083  loss_rpn_loc: 0.01076  time: 0.6694  data_time: 0.0079  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:39:10 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4999  total_loss: 0.4096  loss_cls: 0.07443  loss_box_reg: 0.1795  loss_mask: 0.1408  loss_rpn_cls: 0.0003365  loss_rpn_loc: 0.01095  time: 0.6693  data_time: 0.0067  lr: 0.001  max_mem: 2774M\n",
            "\u001b[32m[06/30 02:39:10 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 0:55:45 (0.6693 s / it)\n",
            "\u001b[32m[06/30 02:39:10 d2.engine.hooks]: \u001b[0mTotal training time: 0:55:50 (0:00:05 on hooks)\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:39:10 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[06/30 02:39:10 d2.data.datasets.coco]: \u001b[0mLoaded 433 images in COCO format from ./drive/MyDrive/졸업과제/annotations2.json\n",
            "\u001b[32m[06/30 02:39:10 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
            "\u001b[32m[06/30 02:39:10 d2.data.common]: \u001b[0mSerializing 433 elements to byte tensors and concatenating them all ...\n",
            "\u001b[32m[06/30 02:39:10 d2.data.common]: \u001b[0mSerialized dataset takes 0.61 MiB\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/30 02:39:10 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./drive/MyDrive/졸업과제/cfg_file/0630.pickle\", 'rb') as f:\n",
        "    cfg = pickle.load(f)\n",
        "# cfg = get_train_cfg(config_file_path, checkpoint_url, train_dataset_name, test_dataset_name, num_classes, device, output_dir)   \n",
        "cfg.MODEL.WEIGHTS = \"./drive/MyDrive/졸업과제/output2/model_final.pth\"\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "_GNFPrMA-B27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0e68368-6d22-42a5-b17d-2f0590a45650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m[06/30 02:56:24 d2.checkpoint.c2_model_loading]: \u001b[0mFollowing weights matched with model:\n",
            "| Names in Model                                  | Names in Checkpoint                                                                                  | Shapes                                          |\n",
            "|:------------------------------------------------|:-----------------------------------------------------------------------------------------------------|:------------------------------------------------|\n",
            "| backbone.bottom_up.res2.0.conv1.*               | backbone.bottom_up.res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |\n",
            "| backbone.bottom_up.res2.0.conv2.*               | backbone.bottom_up.res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.0.conv3.*               | backbone.bottom_up.res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.0.shortcut.*            | backbone.bottom_up.res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.1.conv1.*               | backbone.bottom_up.res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| backbone.bottom_up.res2.1.conv2.*               | backbone.bottom_up.res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.1.conv3.*               | backbone.bottom_up.res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res2.2.conv1.*               | backbone.bottom_up.res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |\n",
            "| backbone.bottom_up.res2.2.conv2.*               | backbone.bottom_up.res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |\n",
            "| backbone.bottom_up.res2.2.conv3.*               | backbone.bottom_up.res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |\n",
            "| backbone.bottom_up.res3.0.conv1.*               | backbone.bottom_up.res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |\n",
            "| backbone.bottom_up.res3.0.conv2.*               | backbone.bottom_up.res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.0.conv3.*               | backbone.bottom_up.res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.0.shortcut.*            | backbone.bottom_up.res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv1.*               | backbone.bottom_up.res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.1.conv2.*               | backbone.bottom_up.res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.1.conv3.*               | backbone.bottom_up.res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv1.*               | backbone.bottom_up.res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.2.conv2.*               | backbone.bottom_up.res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.2.conv3.*               | backbone.bottom_up.res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv1.*               | backbone.bottom_up.res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |\n",
            "| backbone.bottom_up.res3.3.conv2.*               | backbone.bottom_up.res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |\n",
            "| backbone.bottom_up.res3.3.conv3.*               | backbone.bottom_up.res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv1.*               | backbone.bottom_up.res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |\n",
            "| backbone.bottom_up.res4.0.conv2.*               | backbone.bottom_up.res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.0.conv3.*               | backbone.bottom_up.res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.0.shortcut.*            | backbone.bottom_up.res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |\n",
            "| backbone.bottom_up.res4.1.conv1.*               | backbone.bottom_up.res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.1.conv2.*               | backbone.bottom_up.res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.1.conv3.*               | backbone.bottom_up.res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.2.conv1.*               | backbone.bottom_up.res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.2.conv2.*               | backbone.bottom_up.res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.2.conv3.*               | backbone.bottom_up.res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.3.conv1.*               | backbone.bottom_up.res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.3.conv2.*               | backbone.bottom_up.res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.3.conv3.*               | backbone.bottom_up.res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.4.conv1.*               | backbone.bottom_up.res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.4.conv2.*               | backbone.bottom_up.res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.4.conv3.*               | backbone.bottom_up.res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res4.5.conv1.*               | backbone.bottom_up.res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |\n",
            "| backbone.bottom_up.res4.5.conv2.*               | backbone.bottom_up.res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |\n",
            "| backbone.bottom_up.res4.5.conv3.*               | backbone.bottom_up.res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |\n",
            "| backbone.bottom_up.res5.0.conv1.*               | backbone.bottom_up.res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |\n",
            "| backbone.bottom_up.res5.0.conv2.*               | backbone.bottom_up.res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.0.conv3.*               | backbone.bottom_up.res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.0.shortcut.*            | backbone.bottom_up.res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |\n",
            "| backbone.bottom_up.res5.1.conv1.*               | backbone.bottom_up.res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.1.conv2.*               | backbone.bottom_up.res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.1.conv3.*               | backbone.bottom_up.res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.res5.2.conv1.*               | backbone.bottom_up.res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |\n",
            "| backbone.bottom_up.res5.2.conv2.*               | backbone.bottom_up.res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |\n",
            "| backbone.bottom_up.res5.2.conv3.*               | backbone.bottom_up.res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |\n",
            "| backbone.bottom_up.stem.conv1.*                 | backbone.bottom_up.stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |\n",
            "| backbone.fpn_lateral2.*                         | backbone.fpn_lateral2.{bias,weight}                                                                  | (256,) (256,256,1,1)                            |\n",
            "| backbone.fpn_lateral3.*                         | backbone.fpn_lateral3.{bias,weight}                                                                  | (256,) (256,512,1,1)                            |\n",
            "| backbone.fpn_lateral4.*                         | backbone.fpn_lateral4.{bias,weight}                                                                  | (256,) (256,1024,1,1)                           |\n",
            "| backbone.fpn_lateral5.*                         | backbone.fpn_lateral5.{bias,weight}                                                                  | (256,) (256,2048,1,1)                           |\n",
            "| backbone.fpn_output2.*                          | backbone.fpn_output2.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output3.*                          | backbone.fpn_output3.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output4.*                          | backbone.fpn_output4.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| backbone.fpn_output5.*                          | backbone.fpn_output5.{bias,weight}                                                                   | (256,) (256,256,3,3)                            |\n",
            "| proposal_generator.rpn_head.anchor_deltas.*     | proposal_generator.rpn_head.anchor_deltas.{bias,weight}                                              | (12,) (12,256,1,1)                              |\n",
            "| proposal_generator.rpn_head.conv.*              | proposal_generator.rpn_head.conv.{bias,weight}                                                       | (256,) (256,256,3,3)                            |\n",
            "| proposal_generator.rpn_head.objectness_logits.* | proposal_generator.rpn_head.objectness_logits.{bias,weight}                                          | (3,) (3,256,1,1)                                |\n",
            "| roi_heads.box_head.fc1.*                        | roi_heads.box_head.fc1.{bias,weight}                                                                 | (1024,) (1024,12544)                            |\n",
            "| roi_heads.box_head.fc2.*                        | roi_heads.box_head.fc2.{bias,weight}                                                                 | (1024,) (1024,1024)                             |\n",
            "| roi_heads.box_predictor.bbox_pred.*             | roi_heads.box_predictor.bbox_pred.{bias,weight}                                                      | (16,) (16,1024)                                 |\n",
            "| roi_heads.box_predictor.cls_score.*             | roi_heads.box_predictor.cls_score.{bias,weight}                                                      | (5,) (5,1024)                                   |\n",
            "| roi_heads.mask_head.deconv.*                    | roi_heads.mask_head.deconv.{bias,weight}                                                             | (256,) (256,256,2,2)                            |\n",
            "| roi_heads.mask_head.mask_fcn1.*                 | roi_heads.mask_head.mask_fcn1.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.mask_fcn2.*                 | roi_heads.mask_head.mask_fcn2.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.mask_fcn3.*                 | roi_heads.mask_head.mask_fcn3.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.mask_fcn4.*                 | roi_heads.mask_head.mask_fcn4.{bias,weight}                                                          | (256,) (256,256,3,3)                            |\n",
            "| roi_heads.mask_head.predictor.*                 | roi_heads.mask_head.predictor.{bias,weight}                                                          | (4,) (4,256,1,1)                                |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"./drive/MyDrive/졸업과제/result/\"\n",
        "img_path = \"./drive/MyDrive/Graduation/video_images\"\n",
        "image_list = os.listdir(img_path)\n",
        "image_list = [file for file in image_list if file.endswith(\".jpg\")]\n",
        "\n",
        "for i in range(len(image_list)):\n",
        "    image_path = os.path.join(img_path, image_list[i])\n",
        "    #result = on_image(image_path, predictor) # Normal\n",
        "    result = direct_cv_blur_detector(image_path, predictor) # Blur\n",
        "    cv2.imwrite(save_path + image_list[i], result)"
      ],
      "metadata": {
        "id": "hNLfRw66I7QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"./drive/MyDrive/졸업과제/TestResult/\"\n",
        "img_path = \"./drive/MyDrive/졸업과제/TestImages\"\n",
        "image_list = os.listdir(img_path)\n",
        "image_list = [file for file in image_list if file.endswith(\".png\")]\n",
        "\n",
        "for i in range(len(image_list)):\n",
        "    image_path = os.path.join(img_path, image_list[i])\n",
        "    #result = on_image(image_path, predictor) # Normal\n",
        "    result = direct_cv_blur_detector(image_path, predictor) # Blur\n",
        "    cv2.imwrite(save_path + image_list[i], result)"
      ],
      "metadata": {
        "id": "dG0TcHb4u9uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SxmmuDzGz2Rw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}